{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tabulate results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "sys.path.append('../src')\n",
    "from read_log_file import read_log_file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "LOG_HOME_DIR = os.path.join('../logs/')\n",
    "assert os.path.isdir(LOG_HOME_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "MODEL_NAMES = ['logistic_regression', 'transformer_encoder', 'bert-base-uncased', 'bert-base-multilingual-cased']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "SETUPS = ['zero', 'few50', 'few100', 'few150', 'few200', 'full', 'trg']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_best_score_from_dict(di: dict) -> dict:\n",
    "    \"\"\"Get max value from a dict\"\"\"\n",
    "    keys_with_max_val = []\n",
    "    # find max value\n",
    "    max_val = -float('inf')\n",
    "    for k, v in di.items():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "    # find all keys with max value\n",
    "    for k, v in di.items():\n",
    "        if v == max_val:\n",
    "            keys_with_max_val.append(k)\n",
    "    return {\n",
    "        'k': keys_with_max_val,\n",
    "        'v': max_val,\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def create_best_results_df(langs: str) -> pd.DataFrame:\n",
    "    results_dict = {}\n",
    "    for model_name in MODEL_NAMES:\n",
    "        results_dict[model_name] = {}\n",
    "        log_dir = os.path.join(LOG_HOME_DIR, langs, model_name)\n",
    "        log_filenames = os.listdir(log_dir)\n",
    "        for fname in log_filenames:\n",
    "            results_dict[model_name][fname] = read_log_file(\n",
    "                log_file_path=os.path.join(log_dir, fname),\n",
    "                plot=False,\n",
    "                verbose=False,\n",
    "            )['best_val_metrics']['f1']\n",
    "\n",
    "    best_results_dict = {'Setup': SETUPS}\n",
    "    best_results_dict.update({model_name: [] for model_name in MODEL_NAMES})\n",
    "    for model_name in MODEL_NAMES:\n",
    "        for setup in SETUPS:\n",
    "            best_results_dict[model_name].append(\n",
    "                get_best_score_from_dict(\n",
    "                    {k: v for k, v in results_dict[model_name].items() if k.startswith(f'{setup}_')}\n",
    "                )['v']\n",
    "            )\n",
    "\n",
    "    best_results_df = pd.DataFrame(best_results_dict)\n",
    "    return best_results_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  4.03it/s]\n"
     ]
    }
   ],
   "source": [
    "best_results_dfs_dict = {}\n",
    "for langs in tqdm(['enbg', 'enar', 'bgen', 'bgar', 'aren', 'arbg']):\n",
    "    best_results_dfs_dict[langs] = create_best_results_df(langs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## en-bg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup  logistic_regression  transformer_encoder  bert-base-uncased  \\\n0    zero             0.508343             0.791592           0.803166   \n1   few50             0.669023             0.805915           0.811297   \n2  few100             0.789056             0.808465           0.812350   \n3  few150             0.801440             0.812891           0.820823   \n4  few200             0.806709             0.811863           0.813044   \n5    full             0.817149             0.812225           0.819922   \n6     trg             0.813775             0.809617           0.820598   \n\n   bert-base-multilingual-cased  \n0                      0.804159  \n1                      0.810629  \n2                      0.815694  \n3                      0.815002  \n4                      0.816025  \n5                      0.826783  \n6                      0.825151  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>0.508343</td>\n      <td>0.791592</td>\n      <td>0.803166</td>\n      <td>0.804159</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>0.669023</td>\n      <td>0.805915</td>\n      <td>0.811297</td>\n      <td>0.810629</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>0.789056</td>\n      <td>0.808465</td>\n      <td>0.812350</td>\n      <td>0.815694</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>0.801440</td>\n      <td>0.812891</td>\n      <td>0.820823</td>\n      <td>0.815002</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>0.806709</td>\n      <td>0.811863</td>\n      <td>0.813044</td>\n      <td>0.816025</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>0.817149</td>\n      <td>0.812225</td>\n      <td>0.819922</td>\n      <td>0.826783</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>0.813775</td>\n      <td>0.809617</td>\n      <td>0.820598</td>\n      <td>0.825151</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results_dfs_dict['enbg']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "best_results_dfs_dict['enbg'].round(4).to_clipboard(index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## en-ar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup  logistic_regression  transformer_encoder  bert-base-uncased  \\\n0    zero             0.459554             0.543634           0.541674   \n1   few50             0.602569             0.628380           0.588368   \n2  few100             0.599670             0.655968           0.631603   \n3  few150             0.620090             0.708560           0.655699   \n4  few200             0.622177             0.714131           0.580542   \n5    full             0.622177             0.714131           0.580542   \n6     trg             0.644527             0.695322           0.581654   \n\n   bert-base-multilingual-cased  \n0                      0.626963  \n1                      0.640045  \n2                      0.699871  \n3                      0.727245  \n4                      0.706095  \n5                      0.706095  \n6                      0.712644  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>0.459554</td>\n      <td>0.543634</td>\n      <td>0.541674</td>\n      <td>0.626963</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>0.602569</td>\n      <td>0.628380</td>\n      <td>0.588368</td>\n      <td>0.640045</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>0.599670</td>\n      <td>0.655968</td>\n      <td>0.631603</td>\n      <td>0.699871</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>0.620090</td>\n      <td>0.708560</td>\n      <td>0.655699</td>\n      <td>0.727245</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>0.622177</td>\n      <td>0.714131</td>\n      <td>0.580542</td>\n      <td>0.706095</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>0.622177</td>\n      <td>0.714131</td>\n      <td>0.580542</td>\n      <td>0.706095</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>0.644527</td>\n      <td>0.695322</td>\n      <td>0.581654</td>\n      <td>0.712644</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results_dfs_dict['enar']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "best_results_dfs_dict['enar'].round(4).to_clipboard(index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bg-en"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup  logistic_regression  transformer_encoder  bert-base-uncased  \\\n0    zero             0.439126             0.528149           0.476081   \n1   few50             0.587053             0.605046           0.604485   \n2  few100             0.590057             0.600062           0.633917   \n3  few150             0.592898             0.594378           0.639445   \n4  few200             0.592521             0.599739           0.647169   \n5    full             0.589093             0.616020           0.682836   \n6     trg             0.568931             0.624487           0.677584   \n\n   bert-base-multilingual-cased  \n0                      0.508174  \n1                      0.595866  \n2                      0.648412  \n3                      0.648841  \n4                      0.659728  \n5                      0.670561  \n6                      0.649745  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>0.439126</td>\n      <td>0.528149</td>\n      <td>0.476081</td>\n      <td>0.508174</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>0.587053</td>\n      <td>0.605046</td>\n      <td>0.604485</td>\n      <td>0.595866</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>0.590057</td>\n      <td>0.600062</td>\n      <td>0.633917</td>\n      <td>0.648412</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>0.592898</td>\n      <td>0.594378</td>\n      <td>0.639445</td>\n      <td>0.648841</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>0.592521</td>\n      <td>0.599739</td>\n      <td>0.647169</td>\n      <td>0.659728</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>0.589093</td>\n      <td>0.616020</td>\n      <td>0.682836</td>\n      <td>0.670561</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>0.568931</td>\n      <td>0.624487</td>\n      <td>0.677584</td>\n      <td>0.649745</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results_dfs_dict['bgen']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "best_results_dfs_dict['bgen'].round(4).to_clipboard(index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bg-ar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup  logistic_regression  transformer_encoder  bert-base-uncased  \\\n0    zero             0.496158             0.583020           0.518447   \n1   few50             0.565675             0.674656           0.557078   \n2  few100             0.645268             0.646060           0.654343   \n3  few150             0.642236             0.688185           0.602460   \n4  few200             0.654307             0.709412           0.608944   \n5    full             0.654307             0.709412           0.608944   \n6     trg             0.480602             0.664462           0.581654   \n\n   bert-base-multilingual-cased  \n0                      0.577075  \n1                      0.606410  \n2                      0.666635  \n3                      0.698114  \n4                      0.676088  \n5                      0.676088  \n6                      0.712644  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>0.496158</td>\n      <td>0.583020</td>\n      <td>0.518447</td>\n      <td>0.577075</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>0.565675</td>\n      <td>0.674656</td>\n      <td>0.557078</td>\n      <td>0.606410</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>0.645268</td>\n      <td>0.646060</td>\n      <td>0.654343</td>\n      <td>0.666635</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>0.642236</td>\n      <td>0.688185</td>\n      <td>0.602460</td>\n      <td>0.698114</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>0.654307</td>\n      <td>0.709412</td>\n      <td>0.608944</td>\n      <td>0.676088</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>0.654307</td>\n      <td>0.709412</td>\n      <td>0.608944</td>\n      <td>0.676088</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>0.480602</td>\n      <td>0.664462</td>\n      <td>0.581654</td>\n      <td>0.712644</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results_dfs_dict['bgar']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "best_results_dfs_dict['bgar'].round(4).to_clipboard(index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ar-en"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup  logistic_regression  transformer_encoder  bert-base-uncased  \\\n0    zero             0.200949             0.489936           0.499624   \n1   few50             0.523237             0.587793           0.609163   \n2  few100             0.511002             0.582618           0.652872   \n3  few150             0.537679             0.607381           0.645421   \n4  few200             0.571547             0.603234           0.635513   \n5    full             0.565071             0.589381           0.664358   \n6     trg             0.568931             0.624487           0.677584   \n\n   bert-base-multilingual-cased  \n0                      0.573033  \n1                      0.597817  \n2                      0.600951  \n3                      0.621036  \n4                      0.641816  \n5                      0.681317  \n6                      0.649745  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>0.200949</td>\n      <td>0.489936</td>\n      <td>0.499624</td>\n      <td>0.573033</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>0.523237</td>\n      <td>0.587793</td>\n      <td>0.609163</td>\n      <td>0.597817</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>0.511002</td>\n      <td>0.582618</td>\n      <td>0.652872</td>\n      <td>0.600951</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>0.537679</td>\n      <td>0.607381</td>\n      <td>0.645421</td>\n      <td>0.621036</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>0.571547</td>\n      <td>0.603234</td>\n      <td>0.635513</td>\n      <td>0.641816</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>0.565071</td>\n      <td>0.589381</td>\n      <td>0.664358</td>\n      <td>0.681317</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>0.568931</td>\n      <td>0.624487</td>\n      <td>0.677584</td>\n      <td>0.649745</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results_dfs_dict['aren']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "best_results_dfs_dict['aren'].round(4).to_clipboard(index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ar-bg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup  logistic_regression  transformer_encoder  bert-base-uncased  \\\n0    zero             0.458805             0.792784           0.807905   \n1   few50             0.794631             0.791141           0.809904   \n2  few100             0.797243             0.814881           0.813654   \n3  few150             0.804574             0.814388           0.817971   \n4  few200             0.802283             0.809488           0.811947   \n5    full             0.813638             0.815279           0.821831   \n6     trg             0.813775             0.809617           0.820598   \n\n   bert-base-multilingual-cased  \n0                      0.802720  \n1                      0.814546  \n2                      0.819369  \n3                      0.822597  \n4                      0.820767  \n5                      0.826400  \n6                      0.825151  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>0.458805</td>\n      <td>0.792784</td>\n      <td>0.807905</td>\n      <td>0.802720</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>0.794631</td>\n      <td>0.791141</td>\n      <td>0.809904</td>\n      <td>0.814546</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>0.797243</td>\n      <td>0.814881</td>\n      <td>0.813654</td>\n      <td>0.819369</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>0.804574</td>\n      <td>0.814388</td>\n      <td>0.817971</td>\n      <td>0.822597</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>0.802283</td>\n      <td>0.809488</td>\n      <td>0.811947</td>\n      <td>0.820767</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>0.813638</td>\n      <td>0.815279</td>\n      <td>0.821831</td>\n      <td>0.826400</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>0.813775</td>\n      <td>0.809617</td>\n      <td>0.820598</td>\n      <td>0.825151</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results_dfs_dict['arbg']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "best_results_dfs_dict['arbg'].round(4).to_clipboard(index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}