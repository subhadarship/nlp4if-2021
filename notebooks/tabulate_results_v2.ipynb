{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tabulate results\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "sys.path.append('../src')\n",
    "from read_log_file import read_log_file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "LOG_HOME_DIR = os.path.join('../logs_v2')\n",
    "assert os.path.isdir(LOG_HOME_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "MODEL_NAMES = ['logistic_regression', 'transformer_encoder', 'bert-base-uncased', 'bert-base-multilingual-cased']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "SETUPS = ['zero', 'few50', 'few100', 'few150', 'few200', 'full', 'trg']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_best_score_from_dict(di: dict) -> dict:\n",
    "    \"\"\"Get max value from a dict\"\"\"\n",
    "    keys_with_max_val = []\n",
    "    # find max value\n",
    "    max_val = -float('inf')\n",
    "    for k, v in di.items():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "    # find all keys with max value\n",
    "    for k, v in di.items():\n",
    "        if v == max_val:\n",
    "            keys_with_max_val.append(k)\n",
    "    return {\n",
    "        'k': keys_with_max_val,\n",
    "        'v': max_val,\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def create_best_results_df(langs: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    results_dict = {}\n",
    "    for model_name in MODEL_NAMES:\n",
    "        results_dict[model_name] = {}\n",
    "        log_dir = os.path.join(LOG_HOME_DIR, langs, model_name)\n",
    "        log_filenames = os.listdir(log_dir)\n",
    "        for fname in log_filenames:\n",
    "            results_dict[model_name][fname] = read_log_file(\n",
    "                log_file_path=os.path.join(log_dir, fname),\n",
    "                plot=False,\n",
    "                verbose=False,\n",
    "            )['best_val_metrics']['f1']\n",
    "\n",
    "    best_results_dict = {'Setup': SETUPS}\n",
    "    best_hparams_dict = {'Setup': SETUPS}\n",
    "    best_results_dict.update({model_name: [] for model_name in MODEL_NAMES})\n",
    "    best_hparams_dict.update({model_name: [] for model_name in MODEL_NAMES})\n",
    "    for model_name in MODEL_NAMES:\n",
    "        for setup in SETUPS:\n",
    "            best_score = get_best_score_from_dict(\n",
    "                {k: v for k, v in results_dict[model_name].items() if k.startswith(f'{setup}_')}\n",
    "            )\n",
    "            best_results_dict[model_name].append(\n",
    "                best_score['v']\n",
    "            )\n",
    "            best_hparams_dict[model_name].append(\n",
    "                best_score['k']\n",
    "            )\n",
    "\n",
    "\n",
    "    best_results_df = pd.DataFrame(best_results_dict)\n",
    "    best_hparams_df = pd.DataFrame(best_hparams_dict)\n",
    "    return best_results_df, best_hparams_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def highlight_best_score(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Highlight best score in each row\"\"\"\n",
    "    return df.style.apply(lambda x: ['background: red' if isinstance(v, float) and v == max(x.iloc[1:]) else '' for v in x], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def tabulate_markdown(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Tabulate in markdown format and bold best scores in each row\"\"\"\n",
    "    df = df.round(4)\n",
    "    for model_name in MODEL_NAMES:\n",
    "        df[model_name] = df[model_name].astype(str)\n",
    "    for idx in range(len(df)):\n",
    "        max_val = max(float(df.iloc[idx][model_name]) for model_name in MODEL_NAMES)\n",
    "        for model_name in MODEL_NAMES:\n",
    "            cell_val = float(df.iloc[idx][model_name])\n",
    "            if cell_val == max_val:\n",
    "                df.at[idx, model_name] = f'**{cell_val}**'\n",
    "            else:\n",
    "                df.at[idx, model_name] = f'{cell_val}'\n",
    "\n",
    "    return tabulate(df, headers='keys', showindex=False, tablefmt='github')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def tabulate_latex(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Tabulate in markdown format and bold best scores in each row\"\"\"\n",
    "    df = df.round(4)\n",
    "    for model_name in MODEL_NAMES:\n",
    "        df[model_name] = df[model_name].astype(str)\n",
    "    for idx in range(len(df)):\n",
    "        max_val = max(float(df.iloc[idx][model_name]) for model_name in MODEL_NAMES)\n",
    "        for model_name in MODEL_NAMES:\n",
    "            cell_val = float(df.iloc[idx][model_name])\n",
    "            if cell_val == max_val:\n",
    "                df.at[idx, model_name] = f'{cell_val}'\n",
    "            else:\n",
    "                df.at[idx, model_name] = f'{cell_val}'\n",
    "\n",
    "    return tabulate(df, headers='keys', showindex=False, tablefmt='latex')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:21<00:00,  3.61s/it]\n"
     ]
    }
   ],
   "source": [
    "best_results_dfs_dict = {}\n",
    "best_hparams_dfs_dict = {}\n",
    "for langs in tqdm(['enbg', 'enar', 'bgen', 'bgar', 'aren', 'arbg']):\n",
    "    best_results_dfs_dict[langs], best_hparams_dfs_dict[langs] = create_best_results_df(langs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## en-bg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x17d72be5eb8>",
      "text/html": "<style  type=\"text/css\" >\n#T_e80c8e4a_9883_11eb_87be_a0cec835c16drow0_col4,#T_e80c8e4a_9883_11eb_87be_a0cec835c16drow1_col4,#T_e80c8e4a_9883_11eb_87be_a0cec835c16drow2_col4,#T_e80c8e4a_9883_11eb_87be_a0cec835c16drow3_col4,#T_e80c8e4a_9883_11eb_87be_a0cec835c16drow4_col4,#T_e80c8e4a_9883_11eb_87be_a0cec835c16drow5_col4,#T_e80c8e4a_9883_11eb_87be_a0cec835c16drow6_col4{\n            background:  red;\n        }</style><table id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Setup</th>        <th class=\"col_heading level0 col1\" >logistic_regression</th>        <th class=\"col_heading level0 col2\" >transformer_encoder</th>        <th class=\"col_heading level0 col3\" >bert-base-uncased</th>        <th class=\"col_heading level0 col4\" >bert-base-multilingual-cased</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow0_col0\" class=\"data row0 col0\" >zero</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow0_col1\" class=\"data row0 col1\" >0.369656</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow0_col2\" class=\"data row0 col2\" >0.803699</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow0_col3\" class=\"data row0 col3\" >0.802720</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow0_col4\" class=\"data row0 col4\" >0.810053</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow1_col0\" class=\"data row1 col0\" >few50</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow1_col1\" class=\"data row1 col1\" >0.775659</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow1_col2\" class=\"data row1 col2\" >0.799576</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow1_col3\" class=\"data row1 col3\" >0.810351</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow1_col4\" class=\"data row1 col4\" >0.818590</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow2_col0\" class=\"data row2 col0\" >few100</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow2_col1\" class=\"data row2 col1\" >0.781497</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow2_col2\" class=\"data row2 col2\" >0.810259</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow2_col3\" class=\"data row2 col3\" >0.816115</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow2_col4\" class=\"data row2 col4\" >0.822725</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow3_col0\" class=\"data row3 col0\" >few150</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow3_col1\" class=\"data row3 col1\" >0.795635</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow3_col2\" class=\"data row3 col2\" >0.819153</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow3_col3\" class=\"data row3 col3\" >0.818532</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow3_col4\" class=\"data row3 col4\" >0.820666</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow4_col0\" class=\"data row4 col0\" >few200</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow4_col1\" class=\"data row4 col1\" >0.807414</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow4_col2\" class=\"data row4 col2\" >0.819964</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow4_col3\" class=\"data row4 col3\" >0.815694</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow4_col4\" class=\"data row4 col4\" >0.824915</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow5_col0\" class=\"data row5 col0\" >full</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow5_col1\" class=\"data row5 col1\" >0.812499</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow5_col2\" class=\"data row5 col2\" >0.814600</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow5_col3\" class=\"data row5 col3\" >0.822458</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow5_col4\" class=\"data row5 col4\" >0.833575</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow6_col0\" class=\"data row6 col0\" >trg</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow6_col1\" class=\"data row6 col1\" >0.813775</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow6_col2\" class=\"data row6 col2\" >0.809617</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow6_col3\" class=\"data row6 col3\" >0.821763</td>\n                        <td id=\"T_e80c8e4a_9883_11eb_87be_a0cec835c16drow6_col4\" class=\"data row6 col4\" >0.843117</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_best_score(best_results_dfs_dict['enbg'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Setup   |   logistic_regression |   transformer_encoder |   bert-base-uncased | bert-base-multilingual-cased   |\n",
      "|---------|-----------------------|-----------------------|---------------------|--------------------------------|\n",
      "| zero    |                0.3697 |                0.8037 |              0.8027 | **0.8101**                     |\n",
      "| few50   |                0.7757 |                0.7996 |              0.8104 | **0.8186**                     |\n",
      "| few100  |                0.7815 |                0.8103 |              0.8161 | **0.8227**                     |\n",
      "| few150  |                0.7956 |                0.8192 |              0.8185 | **0.8207**                     |\n",
      "| few200  |                0.8074 |                0.82   |              0.8157 | **0.8249**                     |\n",
      "| full    |                0.8125 |                0.8146 |              0.8225 | **0.8336**                     |\n",
      "| trg     |                0.8138 |                0.8096 |              0.8218 | **0.8431**                     |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_markdown(best_results_dfs_dict['enbg']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\hline\n",
      " Setup   &   logistic\\_regression &   transformer\\_encoder &   bert-base-uncased &   bert-base-multilingual-cased \\\\\n",
      "\\hline\n",
      " zero    &                0.3697 &                0.8037 &              0.8027 &                         0.8101 \\\\\n",
      " few50   &                0.7757 &                0.7996 &              0.8104 &                         0.8186 \\\\\n",
      " few100  &                0.7815 &                0.8103 &              0.8161 &                         0.8227 \\\\\n",
      " few150  &                0.7956 &                0.8192 &              0.8185 &                         0.8207 \\\\\n",
      " few200  &                0.8074 &                0.82   &              0.8157 &                         0.8249 \\\\\n",
      " full    &                0.8125 &                0.8146 &              0.8225 &                         0.8336 \\\\\n",
      " trg     &                0.8138 &                0.8096 &              0.8218 &                         0.8431 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_latex(best_results_dfs_dict['enbg']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup                                logistic_regression  \\\n0    zero  [zero_hidden256_vocab16000.txt, zero_hidden256...   \n1   few50  [few50_hidden512_vocab16000.txt, few50_hidden5...   \n2  few100  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  few150  [few150_hidden256_vocab16000.txt, few150_hidde...   \n4  few200  [few200_hidden128_vocab16000.txt, few200_hidde...   \n5    full  [full_hidden256_vocab16000.txt, full_hidden256...   \n6     trg  [trg_hidden256_vocab16000.txt, trg_hidden256_v...   \n\n                                 transformer_encoder  \\\n0  [zero_hidden512_vocab16000.txt, zero_hidden512...   \n1  [few50_hidden512_vocab16000.txt, few50_hidden5...   \n2  [few100_hidden256_vocab16000.txt, few100_hidde...   \n3  [few150_hidden256_vocab16000.txt, few150_hidde...   \n4  [few200_hidden128_vocab16000.txt, few200_hidde...   \n5  [full_hidden512_vocab16000.txt, full_hidden512...   \n6  [trg_hidden256_vocab16000.txt, trg_hidden256_v...   \n\n                                   bert-base-uncased  \\\n0  [zero_fc128_lr0.0005_trainable.txt, zero_fc128...   \n1                  [few50_fc128_lr0.0005_frozen.txt]   \n2                  [few100_fc128_lr0.005_frozen.txt]   \n3                 [few150_fc512_lr0.0005_frozen.txt]   \n4                 [few200_fc256_lr0.0005_frozen.txt]   \n5                   [full_fc512_lr0.0005_frozen.txt]   \n6                    [trg_fc128_lr0.0005_frozen.txt]   \n\n        bert-base-multilingual-cased  \n0    [zero_fc512_lr0.005_frozen.txt]  \n1   [few50_fc256_lr0.005_frozen.txt]  \n2  [few100_fc512_lr0.005_frozen.txt]  \n3  [few150_fc128_lr0.005_frozen.txt]  \n4  [few200_fc512_lr0.005_frozen.txt]  \n5   [full_fc256_lr0.0005_frozen.txt]  \n6    [trg_fc512_lr0.0005_frozen.txt]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>[zero_hidden256_vocab16000.txt, zero_hidden256...</td>\n      <td>[zero_hidden512_vocab16000.txt, zero_hidden512...</td>\n      <td>[zero_fc128_lr0.0005_trainable.txt, zero_fc128...</td>\n      <td>[zero_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>[few50_hidden512_vocab16000.txt, few50_hidden5...</td>\n      <td>[few50_hidden512_vocab16000.txt, few50_hidden5...</td>\n      <td>[few50_fc128_lr0.0005_frozen.txt]</td>\n      <td>[few50_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_hidden256_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_fc128_lr0.005_frozen.txt]</td>\n      <td>[few100_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>[few150_hidden256_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_hidden256_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few150_fc128_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>[few200_hidden128_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_hidden128_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_fc256_lr0.0005_frozen.txt]</td>\n      <td>[few200_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>[full_hidden256_vocab16000.txt, full_hidden256...</td>\n      <td>[full_hidden512_vocab16000.txt, full_hidden512...</td>\n      <td>[full_fc512_lr0.0005_frozen.txt]</td>\n      <td>[full_fc256_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>[trg_hidden256_vocab16000.txt, trg_hidden256_v...</td>\n      <td>[trg_hidden256_vocab16000.txt, trg_hidden256_v...</td>\n      <td>[trg_fc128_lr0.0005_frozen.txt]</td>\n      <td>[trg_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams_dfs_dict['enbg']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## en-ar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x17d72d59748>",
      "text/html": "<style  type=\"text/css\" >\n#T_e821e09a_9883_11eb_b385_a0cec835c16drow0_col4,#T_e821e09a_9883_11eb_b385_a0cec835c16drow1_col4,#T_e821e09a_9883_11eb_b385_a0cec835c16drow2_col4,#T_e821e09a_9883_11eb_b385_a0cec835c16drow3_col4,#T_e821e09a_9883_11eb_b385_a0cec835c16drow4_col4,#T_e821e09a_9883_11eb_b385_a0cec835c16drow5_col4,#T_e821e09a_9883_11eb_b385_a0cec835c16drow6_col4{\n            background:  red;\n        }</style><table id=\"T_e821e09a_9883_11eb_b385_a0cec835c16d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Setup</th>        <th class=\"col_heading level0 col1\" >logistic_regression</th>        <th class=\"col_heading level0 col2\" >transformer_encoder</th>        <th class=\"col_heading level0 col3\" >bert-base-uncased</th>        <th class=\"col_heading level0 col4\" >bert-base-multilingual-cased</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_e821e09a_9883_11eb_b385_a0cec835c16dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow0_col0\" class=\"data row0 col0\" >zero</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow0_col1\" class=\"data row0 col1\" >0.422418</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow0_col2\" class=\"data row0 col2\" >0.584852</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow0_col3\" class=\"data row0 col3\" >0.598659</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow0_col4\" class=\"data row0 col4\" >0.672059</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e821e09a_9883_11eb_b385_a0cec835c16dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow1_col0\" class=\"data row1 col0\" >few50</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow1_col1\" class=\"data row1 col1\" >0.727199</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow1_col2\" class=\"data row1 col2\" >0.689753</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow1_col3\" class=\"data row1 col3\" >0.675045</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow1_col4\" class=\"data row1 col4\" >0.774892</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e821e09a_9883_11eb_b385_a0cec835c16dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow2_col0\" class=\"data row2 col0\" >few100</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow2_col1\" class=\"data row2 col1\" >0.743307</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow2_col2\" class=\"data row2 col2\" >0.685501</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow2_col3\" class=\"data row2 col3\" >0.691503</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow2_col4\" class=\"data row2 col4\" >0.824014</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e821e09a_9883_11eb_b385_a0cec835c16dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow3_col0\" class=\"data row3 col0\" >few150</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow3_col1\" class=\"data row3 col1\" >0.718456</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow3_col2\" class=\"data row3 col2\" >0.688997</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow3_col3\" class=\"data row3 col3\" >0.697930</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow3_col4\" class=\"data row3 col4\" >0.791109</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e821e09a_9883_11eb_b385_a0cec835c16dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow4_col0\" class=\"data row4 col0\" >few200</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow4_col1\" class=\"data row4 col1\" >0.747128</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow4_col2\" class=\"data row4 col2\" >0.739566</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow4_col3\" class=\"data row4 col3\" >0.711928</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow4_col4\" class=\"data row4 col4\" >0.786594</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e821e09a_9883_11eb_b385_a0cec835c16dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow5_col0\" class=\"data row5 col0\" >full</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow5_col1\" class=\"data row5 col1\" >0.747128</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow5_col2\" class=\"data row5 col2\" >0.739566</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow5_col3\" class=\"data row5 col3\" >0.711928</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow5_col4\" class=\"data row5 col4\" >0.786594</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e821e09a_9883_11eb_b385_a0cec835c16dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow6_col0\" class=\"data row6 col0\" >trg</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow6_col1\" class=\"data row6 col1\" >0.648866</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow6_col2\" class=\"data row6 col2\" >0.684390</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow6_col3\" class=\"data row6 col3\" >0.734822</td>\n                        <td id=\"T_e821e09a_9883_11eb_b385_a0cec835c16drow6_col4\" class=\"data row6 col4\" >0.738182</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_best_score(best_results_dfs_dict['enar'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Setup   |   logistic_regression |   transformer_encoder |   bert-base-uncased | bert-base-multilingual-cased   |\n",
      "|---------|-----------------------|-----------------------|---------------------|--------------------------------|\n",
      "| zero    |                0.4224 |                0.5849 |              0.5987 | **0.6721**                     |\n",
      "| few50   |                0.7272 |                0.6898 |              0.675  | **0.7749**                     |\n",
      "| few100  |                0.7433 |                0.6855 |              0.6915 | **0.824**                      |\n",
      "| few150  |                0.7185 |                0.689  |              0.6979 | **0.7911**                     |\n",
      "| few200  |                0.7471 |                0.7396 |              0.7119 | **0.7866**                     |\n",
      "| full    |                0.7471 |                0.7396 |              0.7119 | **0.7866**                     |\n",
      "| trg     |                0.6489 |                0.6844 |              0.7348 | **0.7382**                     |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_markdown(best_results_dfs_dict['enar']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(tabulate_latex(best_results_dfs_dict['enar']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\hline\n",
      " Setup   &   logistic\\_regression &   transformer\\_encoder &   bert-base-uncased &   bert-base-multilingual-cased \\\\\n",
      "\\hline\n",
      " zero    &                0.4224 &                0.5849 &              0.5987 &                         0.6721 \\\\\n",
      " few50   &                0.7272 &                0.6898 &              0.675  &                         0.7749 \\\\\n",
      " few100  &                0.7433 &                0.6855 &              0.6915 &                         0.824  \\\\\n",
      " few150  &                0.7185 &                0.689  &              0.6979 &                         0.7911 \\\\\n",
      " few200  &                0.7471 &                0.7396 &              0.7119 &                         0.7866 \\\\\n",
      " full    &                0.7471 &                0.7396 &              0.7119 &                         0.7866 \\\\\n",
      " trg     &                0.6489 &                0.6844 &              0.7348 &                         0.7382 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup                                logistic_regression  \\\n0    zero  [zero_hidden128_vocab16000.txt, zero_hidden128...   \n1   few50  [few50_hidden512_vocab16000.txt, few50_hidden5...   \n2  few100  [few100_hidden256_vocab16000.txt, few100_hidde...   \n3  few150  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  few200  [few200_hidden512_vocab16000.txt, few200_hidde...   \n5    full  [full_hidden512_vocab16000.txt, full_hidden512...   \n6     trg  [trg_hidden128_vocab16000.txt, trg_hidden128_v...   \n\n                                 transformer_encoder  \\\n0  [zero_hidden512_vocab16000.txt, zero_hidden512...   \n1  [few50_hidden128_vocab16000.txt, few50_hidden1...   \n2  [few100_hidden128_vocab16000.txt, few100_hidde...   \n3  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  [few200_hidden512_vocab16000.txt, few200_hidde...   \n5  [full_hidden512_vocab16000.txt, full_hidden512...   \n6  [trg_hidden256_vocab16000.txt, trg_hidden256_v...   \n\n                    bert-base-uncased        bert-base-multilingual-cased  \n0    [zero_fc128_lr0.0005_frozen.txt]     [zero_fc512_lr0.005_frozen.txt]  \n1   [few50_fc128_lr0.0005_frozen.txt]   [few50_fc128_lr0.0005_frozen.txt]  \n2  [few100_fc256_lr0.0005_frozen.txt]   [few100_fc512_lr0.005_frozen.txt]  \n3   [few150_fc512_lr0.005_frozen.txt]  [few150_fc512_lr0.0005_frozen.txt]  \n4  [few200_fc256_lr0.0005_frozen.txt]   [few200_fc512_lr0.005_frozen.txt]  \n5    [full_fc256_lr0.0005_frozen.txt]     [full_fc512_lr0.005_frozen.txt]  \n6     [trg_fc512_lr0.0005_frozen.txt]      [trg_fc512_lr0.005_frozen.txt]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>[zero_hidden128_vocab16000.txt, zero_hidden128...</td>\n      <td>[zero_hidden512_vocab16000.txt, zero_hidden512...</td>\n      <td>[zero_fc128_lr0.0005_frozen.txt]</td>\n      <td>[zero_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>[few50_hidden512_vocab16000.txt, few50_hidden5...</td>\n      <td>[few50_hidden128_vocab16000.txt, few50_hidden1...</td>\n      <td>[few50_fc128_lr0.0005_frozen.txt]</td>\n      <td>[few50_fc128_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>[few100_hidden256_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_hidden128_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_fc256_lr0.0005_frozen.txt]</td>\n      <td>[few100_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_fc512_lr0.005_frozen.txt]</td>\n      <td>[few150_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>[few200_hidden512_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_hidden512_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_fc256_lr0.0005_frozen.txt]</td>\n      <td>[few200_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>[full_hidden512_vocab16000.txt, full_hidden512...</td>\n      <td>[full_hidden512_vocab16000.txt, full_hidden512...</td>\n      <td>[full_fc256_lr0.0005_frozen.txt]</td>\n      <td>[full_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>[trg_hidden128_vocab16000.txt, trg_hidden128_v...</td>\n      <td>[trg_hidden256_vocab16000.txt, trg_hidden256_v...</td>\n      <td>[trg_fc512_lr0.0005_frozen.txt]</td>\n      <td>[trg_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams_dfs_dict['enar']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bg-en"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x17d72be5b70>",
      "text/html": "<style  type=\"text/css\" >\n#T_e839773e_9883_11eb_b957_a0cec835c16drow0_col4,#T_e839773e_9883_11eb_b957_a0cec835c16drow1_col4,#T_e839773e_9883_11eb_b957_a0cec835c16drow2_col4,#T_e839773e_9883_11eb_b957_a0cec835c16drow3_col4,#T_e839773e_9883_11eb_b957_a0cec835c16drow4_col3,#T_e839773e_9883_11eb_b957_a0cec835c16drow5_col3,#T_e839773e_9883_11eb_b957_a0cec835c16drow6_col3{\n            background:  red;\n        }</style><table id=\"T_e839773e_9883_11eb_b957_a0cec835c16d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Setup</th>        <th class=\"col_heading level0 col1\" >logistic_regression</th>        <th class=\"col_heading level0 col2\" >transformer_encoder</th>        <th class=\"col_heading level0 col3\" >bert-base-uncased</th>        <th class=\"col_heading level0 col4\" >bert-base-multilingual-cased</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_e839773e_9883_11eb_b957_a0cec835c16dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow0_col0\" class=\"data row0 col0\" >zero</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow0_col1\" class=\"data row0 col1\" >0.522791</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow0_col2\" class=\"data row0 col2\" >0.569252</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow0_col3\" class=\"data row0 col3\" >0.487918</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow0_col4\" class=\"data row0 col4\" >0.684943</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e839773e_9883_11eb_b957_a0cec835c16dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow1_col0\" class=\"data row1 col0\" >few50</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow1_col1\" class=\"data row1 col1\" >0.600851</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow1_col2\" class=\"data row1 col2\" >0.577882</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow1_col3\" class=\"data row1 col3\" >0.642544</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow1_col4\" class=\"data row1 col4\" >0.671831</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e839773e_9883_11eb_b957_a0cec835c16dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow2_col0\" class=\"data row2 col0\" >few100</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow2_col1\" class=\"data row2 col1\" >0.607478</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow2_col2\" class=\"data row2 col2\" >0.618867</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow2_col3\" class=\"data row2 col3\" >0.620778</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow2_col4\" class=\"data row2 col4\" >0.658960</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e839773e_9883_11eb_b957_a0cec835c16dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow3_col0\" class=\"data row3 col0\" >few150</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow3_col1\" class=\"data row3 col1\" >0.635134</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow3_col2\" class=\"data row3 col2\" >0.609627</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow3_col3\" class=\"data row3 col3\" >0.631913</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow3_col4\" class=\"data row3 col4\" >0.655309</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e839773e_9883_11eb_b957_a0cec835c16dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow4_col0\" class=\"data row4 col0\" >few200</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow4_col1\" class=\"data row4 col1\" >0.674276</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow4_col2\" class=\"data row4 col2\" >0.635436</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow4_col3\" class=\"data row4 col3\" >0.712940</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow4_col4\" class=\"data row4 col4\" >0.696439</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e839773e_9883_11eb_b957_a0cec835c16dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow5_col0\" class=\"data row5 col0\" >full</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow5_col1\" class=\"data row5 col1\" >0.713038</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow5_col2\" class=\"data row5 col2\" >0.670283</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow5_col3\" class=\"data row5 col3\" >0.728505</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow5_col4\" class=\"data row5 col4\" >0.699864</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e839773e_9883_11eb_b957_a0cec835c16dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow6_col0\" class=\"data row6 col0\" >trg</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow6_col1\" class=\"data row6 col1\" >0.698497</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow6_col2\" class=\"data row6 col2\" >0.686484</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow6_col3\" class=\"data row6 col3\" >0.744600</td>\n                        <td id=\"T_e839773e_9883_11eb_b957_a0cec835c16drow6_col4\" class=\"data row6 col4\" >0.722145</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_best_score(best_results_dfs_dict['bgen'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Setup   |   logistic_regression |   transformer_encoder | bert-base-uncased   | bert-base-multilingual-cased   |\n",
      "|---------|-----------------------|-----------------------|---------------------|--------------------------------|\n",
      "| zero    |                0.5228 |                0.5693 | 0.4879              | **0.6849**                     |\n",
      "| few50   |                0.6009 |                0.5779 | 0.6425              | **0.6718**                     |\n",
      "| few100  |                0.6075 |                0.6189 | 0.6208              | **0.659**                      |\n",
      "| few150  |                0.6351 |                0.6096 | 0.6319              | **0.6553**                     |\n",
      "| few200  |                0.6743 |                0.6354 | **0.7129**          | 0.6964                         |\n",
      "| full    |                0.713  |                0.6703 | **0.7285**          | 0.6999                         |\n",
      "| trg     |                0.6985 |                0.6865 | **0.7446**          | 0.7221                         |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_markdown(best_results_dfs_dict['bgen']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(tabulate_latex(best_results_dfs_dict['bgen']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\hline\n",
      " Setup   &   logistic\\_regression &   transformer\\_encoder &   bert-base-uncased &   bert-base-multilingual-cased \\\\\n",
      "\\hline\n",
      " zero    &                0.5228 &                0.5693 &              0.4879 &                         0.6849 \\\\\n",
      " few50   &                0.6009 &                0.5779 &              0.6425 &                         0.6718 \\\\\n",
      " few100  &                0.6075 &                0.6189 &              0.6208 &                         0.659  \\\\\n",
      " few150  &                0.6351 &                0.6096 &              0.6319 &                         0.6553 \\\\\n",
      " few200  &                0.6743 &                0.6354 &              0.7129 &                         0.6964 \\\\\n",
      " full    &                0.713  &                0.6703 &              0.7285 &                         0.6999 \\\\\n",
      " trg     &                0.6985 &                0.6865 &              0.7446 &                         0.7221 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup                                logistic_regression  \\\n0    zero  [zero_hidden128_vocab16000.txt, zero_hidden128...   \n1   few50  [few50_hidden128_vocab16000.txt, few50_hidden1...   \n2  few100  [few100_hidden128_vocab16000.txt, few100_hidde...   \n3  few150  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  few200  [few200_hidden128_vocab16000.txt, few200_hidde...   \n5    full  [full_hidden512_vocab16000.txt, full_hidden512...   \n6     trg  [trg_hidden512_vocab16000.txt, trg_hidden512_v...   \n\n                                 transformer_encoder  \\\n0  [zero_hidden256_vocab16000.txt, zero_hidden256...   \n1  [few50_hidden128_vocab16000.txt, few50_hidden1...   \n2  [few100_hidden128_vocab16000.txt, few100_hidde...   \n3  [few150_hidden128_vocab16000.txt, few150_hidde...   \n4  [few200_hidden256_vocab16000.txt, few200_hidde...   \n5  [full_hidden128_vocab16000.txt, full_hidden128...   \n6  [trg_hidden128_vocab16000.txt, trg_hidden128_v...   \n\n                    bert-base-uncased        bert-base-multilingual-cased  \n0      [zero_fc256_lr0.05_frozen.txt]    [zero_fc512_lr0.0005_frozen.txt]  \n1   [few50_fc512_lr0.0005_frozen.txt]   [few50_fc128_lr0.0005_frozen.txt]  \n2  [few100_fc256_lr0.0005_frozen.txt]  [few100_fc256_lr0.0005_frozen.txt]  \n3  [few150_fc512_lr0.0005_frozen.txt]  [few150_fc512_lr0.0005_frozen.txt]  \n4  [few200_fc512_lr0.0005_frozen.txt]  [few200_fc256_lr0.0005_frozen.txt]  \n5     [full_fc512_lr0.005_frozen.txt]     [full_fc256_lr0.005_frozen.txt]  \n6      [trg_fc256_lr0.005_frozen.txt]      [trg_fc256_lr0.005_frozen.txt]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>[zero_hidden128_vocab16000.txt, zero_hidden128...</td>\n      <td>[zero_hidden256_vocab16000.txt, zero_hidden256...</td>\n      <td>[zero_fc256_lr0.05_frozen.txt]</td>\n      <td>[zero_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>[few50_hidden128_vocab16000.txt, few50_hidden1...</td>\n      <td>[few50_hidden128_vocab16000.txt, few50_hidden1...</td>\n      <td>[few50_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few50_fc128_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>[few100_hidden128_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_hidden128_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_fc256_lr0.0005_frozen.txt]</td>\n      <td>[few100_fc256_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_hidden128_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few150_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>[few200_hidden128_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_hidden256_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few200_fc256_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>[full_hidden512_vocab16000.txt, full_hidden512...</td>\n      <td>[full_hidden128_vocab16000.txt, full_hidden128...</td>\n      <td>[full_fc512_lr0.005_frozen.txt]</td>\n      <td>[full_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>[trg_hidden512_vocab16000.txt, trg_hidden512_v...</td>\n      <td>[trg_hidden128_vocab16000.txt, trg_hidden128_v...</td>\n      <td>[trg_fc256_lr0.005_frozen.txt]</td>\n      <td>[trg_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams_dfs_dict['bgen']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bg-ar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x17d72d8ad68>",
      "text/html": "<style  type=\"text/css\" >\n#T_e855af36_9883_11eb_901c_a0cec835c16drow0_col4,#T_e855af36_9883_11eb_901c_a0cec835c16drow1_col4,#T_e855af36_9883_11eb_901c_a0cec835c16drow2_col4,#T_e855af36_9883_11eb_901c_a0cec835c16drow3_col4,#T_e855af36_9883_11eb_901c_a0cec835c16drow4_col4,#T_e855af36_9883_11eb_901c_a0cec835c16drow5_col4,#T_e855af36_9883_11eb_901c_a0cec835c16drow6_col4{\n            background:  red;\n        }</style><table id=\"T_e855af36_9883_11eb_901c_a0cec835c16d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Setup</th>        <th class=\"col_heading level0 col1\" >logistic_regression</th>        <th class=\"col_heading level0 col2\" >transformer_encoder</th>        <th class=\"col_heading level0 col3\" >bert-base-uncased</th>        <th class=\"col_heading level0 col4\" >bert-base-multilingual-cased</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_e855af36_9883_11eb_901c_a0cec835c16dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow0_col0\" class=\"data row0 col0\" >zero</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow0_col1\" class=\"data row0 col1\" >0.547247</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow0_col2\" class=\"data row0 col2\" >0.614746</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow0_col3\" class=\"data row0 col3\" >0.558164</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow0_col4\" class=\"data row0 col4\" >0.638295</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e855af36_9883_11eb_901c_a0cec835c16dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow1_col0\" class=\"data row1 col0\" >few50</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow1_col1\" class=\"data row1 col1\" >0.676276</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow1_col2\" class=\"data row1 col2\" >0.647330</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow1_col3\" class=\"data row1 col3\" >0.657497</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow1_col4\" class=\"data row1 col4\" >0.760313</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e855af36_9883_11eb_901c_a0cec835c16dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow2_col0\" class=\"data row2 col0\" >few100</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow2_col1\" class=\"data row2 col1\" >0.697810</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow2_col2\" class=\"data row2 col2\" >0.733819</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow2_col3\" class=\"data row2 col3\" >0.662149</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow2_col4\" class=\"data row2 col4\" >0.753031</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e855af36_9883_11eb_901c_a0cec835c16dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow3_col0\" class=\"data row3 col0\" >few150</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow3_col1\" class=\"data row3 col1\" >0.725884</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow3_col2\" class=\"data row3 col2\" >0.687609</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow3_col3\" class=\"data row3 col3\" >0.651926</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow3_col4\" class=\"data row3 col4\" >0.775172</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e855af36_9883_11eb_901c_a0cec835c16dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow4_col0\" class=\"data row4 col0\" >few200</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow4_col1\" class=\"data row4 col1\" >0.707694</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow4_col2\" class=\"data row4 col2\" >0.715821</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow4_col3\" class=\"data row4 col3\" >0.679205</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow4_col4\" class=\"data row4 col4\" >0.764396</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e855af36_9883_11eb_901c_a0cec835c16dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow5_col0\" class=\"data row5 col0\" >full</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow5_col1\" class=\"data row5 col1\" >0.707694</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow5_col2\" class=\"data row5 col2\" >0.715821</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow5_col3\" class=\"data row5 col3\" >0.679205</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow5_col4\" class=\"data row5 col4\" >0.764396</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e855af36_9883_11eb_901c_a0cec835c16dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow6_col0\" class=\"data row6 col0\" >trg</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow6_col1\" class=\"data row6 col1\" >0.648866</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow6_col2\" class=\"data row6 col2\" >0.684390</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow6_col3\" class=\"data row6 col3\" >0.734822</td>\n                        <td id=\"T_e855af36_9883_11eb_901c_a0cec835c16drow6_col4\" class=\"data row6 col4\" >0.738182</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_best_score(best_results_dfs_dict['bgar'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Setup   |   logistic_regression |   transformer_encoder |   bert-base-uncased | bert-base-multilingual-cased   |\n",
      "|---------|-----------------------|-----------------------|---------------------|--------------------------------|\n",
      "| zero    |                0.5472 |                0.6147 |              0.5582 | **0.6383**                     |\n",
      "| few50   |                0.6763 |                0.6473 |              0.6575 | **0.7603**                     |\n",
      "| few100  |                0.6978 |                0.7338 |              0.6621 | **0.753**                      |\n",
      "| few150  |                0.7259 |                0.6876 |              0.6519 | **0.7752**                     |\n",
      "| few200  |                0.7077 |                0.7158 |              0.6792 | **0.7644**                     |\n",
      "| full    |                0.7077 |                0.7158 |              0.6792 | **0.7644**                     |\n",
      "| trg     |                0.6489 |                0.6844 |              0.7348 | **0.7382**                     |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_markdown(best_results_dfs_dict['bgar']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\hline\n",
      " Setup   &   logistic\\_regression &   transformer\\_encoder &   bert-base-uncased &   bert-base-multilingual-cased \\\\\n",
      "\\hline\n",
      " zero    &                0.5472 &                0.6147 &              0.5582 &                         0.6383 \\\\\n",
      " few50   &                0.6763 &                0.6473 &              0.6575 &                         0.7603 \\\\\n",
      " few100  &                0.6978 &                0.7338 &              0.6621 &                         0.753  \\\\\n",
      " few150  &                0.7259 &                0.6876 &              0.6519 &                         0.7752 \\\\\n",
      " few200  &                0.7077 &                0.7158 &              0.6792 &                         0.7644 \\\\\n",
      " full    &                0.7077 &                0.7158 &              0.6792 &                         0.7644 \\\\\n",
      " trg     &                0.6489 &                0.6844 &              0.7348 &                         0.7382 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_latex(best_results_dfs_dict['bgar']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup                                logistic_regression  \\\n0    zero  [zero_hidden128_vocab16000.txt, zero_hidden128...   \n1   few50  [few50_hidden512_vocab16000.txt, few50_hidden5...   \n2  few100  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  few150  [few150_hidden256_vocab16000.txt, few150_hidde...   \n4  few200  [few200_hidden256_vocab16000.txt, few200_hidde...   \n5    full  [full_hidden256_vocab16000.txt, full_hidden256...   \n6     trg  [trg_hidden128_vocab16000.txt, trg_hidden128_v...   \n\n                                 transformer_encoder  \\\n0  [zero_hidden256_vocab16000.txt, zero_hidden256...   \n1  [few50_hidden256_vocab16000.txt, few50_hidden2...   \n2  [few100_hidden256_vocab16000.txt, few100_hidde...   \n3  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  [few200_hidden512_vocab16000.txt, few200_hidde...   \n5  [full_hidden512_vocab16000.txt, full_hidden512...   \n6  [trg_hidden256_vocab16000.txt, trg_hidden256_v...   \n\n                                   bert-base-uncased  \\\n0  [zero_fc128_lr0.0005_trainable.txt, zero_fc128...   \n1                  [few50_fc256_lr0.0005_frozen.txt]   \n2                 [few100_fc512_lr0.0005_frozen.txt]   \n3                 [few150_fc128_lr0.0005_frozen.txt]   \n4                 [few200_fc128_lr0.0005_frozen.txt]   \n5                   [full_fc128_lr0.0005_frozen.txt]   \n6                    [trg_fc512_lr0.0005_frozen.txt]   \n\n         bert-base-multilingual-cased  \n0     [zero_fc128_lr0.005_frozen.txt]  \n1   [few50_fc512_lr0.0005_frozen.txt]  \n2  [few100_fc256_lr0.0005_frozen.txt]  \n3  [few150_fc512_lr0.0005_frozen.txt]  \n4  [few200_fc256_lr0.0005_frozen.txt]  \n5    [full_fc256_lr0.0005_frozen.txt]  \n6      [trg_fc512_lr0.005_frozen.txt]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>[zero_hidden128_vocab16000.txt, zero_hidden128...</td>\n      <td>[zero_hidden256_vocab16000.txt, zero_hidden256...</td>\n      <td>[zero_fc128_lr0.0005_trainable.txt, zero_fc128...</td>\n      <td>[zero_fc128_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>[few50_hidden512_vocab16000.txt, few50_hidden5...</td>\n      <td>[few50_hidden256_vocab16000.txt, few50_hidden2...</td>\n      <td>[few50_fc256_lr0.0005_frozen.txt]</td>\n      <td>[few50_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_hidden256_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few100_fc256_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>[few150_hidden256_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_fc128_lr0.0005_frozen.txt]</td>\n      <td>[few150_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>[few200_hidden256_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_hidden512_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_fc128_lr0.0005_frozen.txt]</td>\n      <td>[few200_fc256_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>[full_hidden256_vocab16000.txt, full_hidden256...</td>\n      <td>[full_hidden512_vocab16000.txt, full_hidden512...</td>\n      <td>[full_fc128_lr0.0005_frozen.txt]</td>\n      <td>[full_fc256_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>[trg_hidden128_vocab16000.txt, trg_hidden128_v...</td>\n      <td>[trg_hidden256_vocab16000.txt, trg_hidden256_v...</td>\n      <td>[trg_fc512_lr0.0005_frozen.txt]</td>\n      <td>[trg_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams_dfs_dict['bgar']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ar-en"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x17d72d8f2b0>",
      "text/html": "<style  type=\"text/css\" >\n#T_e8694318_9883_11eb_88ec_a0cec835c16drow0_col4,#T_e8694318_9883_11eb_88ec_a0cec835c16drow1_col4,#T_e8694318_9883_11eb_88ec_a0cec835c16drow2_col4,#T_e8694318_9883_11eb_88ec_a0cec835c16drow3_col3,#T_e8694318_9883_11eb_88ec_a0cec835c16drow4_col3,#T_e8694318_9883_11eb_88ec_a0cec835c16drow5_col3,#T_e8694318_9883_11eb_88ec_a0cec835c16drow6_col3{\n            background:  red;\n        }</style><table id=\"T_e8694318_9883_11eb_88ec_a0cec835c16d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Setup</th>        <th class=\"col_heading level0 col1\" >logistic_regression</th>        <th class=\"col_heading level0 col2\" >transformer_encoder</th>        <th class=\"col_heading level0 col3\" >bert-base-uncased</th>        <th class=\"col_heading level0 col4\" >bert-base-multilingual-cased</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_e8694318_9883_11eb_88ec_a0cec835c16dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow0_col0\" class=\"data row0 col0\" >zero</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow0_col1\" class=\"data row0 col1\" >0.435813</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow0_col2\" class=\"data row0 col2\" >0.516790</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow0_col3\" class=\"data row0 col3\" >0.593767</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow0_col4\" class=\"data row0 col4\" >0.683008</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e8694318_9883_11eb_88ec_a0cec835c16dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow1_col0\" class=\"data row1 col0\" >few50</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow1_col1\" class=\"data row1 col1\" >0.536712</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow1_col2\" class=\"data row1 col2\" >0.553041</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow1_col3\" class=\"data row1 col3\" >0.630206</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow1_col4\" class=\"data row1 col4\" >0.658884</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e8694318_9883_11eb_88ec_a0cec835c16dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow2_col0\" class=\"data row2 col0\" >few100</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow2_col1\" class=\"data row2 col1\" >0.622074</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow2_col2\" class=\"data row2 col2\" >0.608997</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow2_col3\" class=\"data row2 col3\" >0.639147</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow2_col4\" class=\"data row2 col4\" >0.662509</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e8694318_9883_11eb_88ec_a0cec835c16dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow3_col0\" class=\"data row3 col0\" >few150</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow3_col1\" class=\"data row3 col1\" >0.626780</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow3_col2\" class=\"data row3 col2\" >0.610483</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow3_col3\" class=\"data row3 col3\" >0.728866</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow3_col4\" class=\"data row3 col4\" >0.664647</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e8694318_9883_11eb_88ec_a0cec835c16dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow4_col0\" class=\"data row4 col0\" >few200</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow4_col1\" class=\"data row4 col1\" >0.661438</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow4_col2\" class=\"data row4 col2\" >0.686012</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow4_col3\" class=\"data row4 col3\" >0.721739</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow4_col4\" class=\"data row4 col4\" >0.679520</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e8694318_9883_11eb_88ec_a0cec835c16dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow5_col0\" class=\"data row5 col0\" >full</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow5_col1\" class=\"data row5 col1\" >0.715435</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow5_col2\" class=\"data row5 col2\" >0.680290</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow5_col3\" class=\"data row5 col3\" >0.745004</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow5_col4\" class=\"data row5 col4\" >0.711777</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e8694318_9883_11eb_88ec_a0cec835c16dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow6_col0\" class=\"data row6 col0\" >trg</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow6_col1\" class=\"data row6 col1\" >0.698497</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow6_col2\" class=\"data row6 col2\" >0.686484</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow6_col3\" class=\"data row6 col3\" >0.744600</td>\n                        <td id=\"T_e8694318_9883_11eb_88ec_a0cec835c16drow6_col4\" class=\"data row6 col4\" >0.722145</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_best_score(best_results_dfs_dict['aren'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Setup   |   logistic_regression |   transformer_encoder | bert-base-uncased   | bert-base-multilingual-cased   |\n",
      "|---------|-----------------------|-----------------------|---------------------|--------------------------------|\n",
      "| zero    |                0.4358 |                0.5168 | 0.5938              | **0.683**                      |\n",
      "| few50   |                0.5367 |                0.553  | 0.6302              | **0.6589**                     |\n",
      "| few100  |                0.6221 |                0.609  | 0.6391              | **0.6625**                     |\n",
      "| few150  |                0.6268 |                0.6105 | **0.7289**          | 0.6646                         |\n",
      "| few200  |                0.6614 |                0.686  | **0.7217**          | 0.6795                         |\n",
      "| full    |                0.7154 |                0.6803 | **0.745**           | 0.7118                         |\n",
      "| trg     |                0.6985 |                0.6865 | **0.7446**          | 0.7221                         |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_markdown(best_results_dfs_dict['aren']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\hline\n",
      " Setup   &   logistic\\_regression &   transformer\\_encoder &   bert-base-uncased &   bert-base-multilingual-cased \\\\\n",
      "\\hline\n",
      " zero    &                0.4358 &                0.5168 &              0.5938 &                         0.683  \\\\\n",
      " few50   &                0.5367 &                0.553  &              0.6302 &                         0.6589 \\\\\n",
      " few100  &                0.6221 &                0.609  &              0.6391 &                         0.6625 \\\\\n",
      " few150  &                0.6268 &                0.6105 &              0.7289 &                         0.6646 \\\\\n",
      " few200  &                0.6614 &                0.686  &              0.7217 &                         0.6795 \\\\\n",
      " full    &                0.7154 &                0.6803 &              0.745  &                         0.7118 \\\\\n",
      " trg     &                0.6985 &                0.6865 &              0.7446 &                         0.7221 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_latex(best_results_dfs_dict['aren']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup                                logistic_regression  \\\n0    zero  [zero_hidden128_vocab16000.txt, zero_hidden128...   \n1   few50  [few50_hidden256_vocab16000.txt, few50_hidden2...   \n2  few100  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  few150  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  few200  [few200_hidden256_vocab16000.txt, few200_hidde...   \n5    full  [full_hidden256_vocab16000.txt, full_hidden256...   \n6     trg  [trg_hidden512_vocab16000.txt, trg_hidden512_v...   \n\n                                 transformer_encoder  \\\n0  [zero_hidden256_vocab16000.txt, zero_hidden256...   \n1  [few50_hidden128_vocab16000.txt, few50_hidden1...   \n2  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  [few150_hidden128_vocab16000.txt, few150_hidde...   \n4  [few200_hidden128_vocab16000.txt, few200_hidde...   \n5  [full_hidden512_vocab16000.txt, full_hidden512...   \n6  [trg_hidden128_vocab16000.txt, trg_hidden128_v...   \n\n                    bert-base-uncased        bert-base-multilingual-cased  \n0    [zero_fc512_lr0.0005_frozen.txt]     [zero_fc512_lr0.005_frozen.txt]  \n1    [few50_fc512_lr0.005_frozen.txt]    [few50_fc256_lr0.005_frozen.txt]  \n2   [few100_fc128_lr0.005_frozen.txt]   [few100_fc512_lr0.005_frozen.txt]  \n3   [few150_fc512_lr0.005_frozen.txt]  [few150_fc512_lr0.0005_frozen.txt]  \n4  [few200_fc512_lr0.0005_frozen.txt]   [few200_fc256_lr0.005_frozen.txt]  \n5    [full_fc512_lr0.0005_frozen.txt]     [full_fc512_lr0.005_frozen.txt]  \n6      [trg_fc256_lr0.005_frozen.txt]      [trg_fc256_lr0.005_frozen.txt]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>[zero_hidden128_vocab16000.txt, zero_hidden128...</td>\n      <td>[zero_hidden256_vocab16000.txt, zero_hidden256...</td>\n      <td>[zero_fc512_lr0.0005_frozen.txt]</td>\n      <td>[zero_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>[few50_hidden256_vocab16000.txt, few50_hidden2...</td>\n      <td>[few50_hidden128_vocab16000.txt, few50_hidden1...</td>\n      <td>[few50_fc512_lr0.005_frozen.txt]</td>\n      <td>[few50_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_fc128_lr0.005_frozen.txt]</td>\n      <td>[few100_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_hidden128_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_fc512_lr0.005_frozen.txt]</td>\n      <td>[few150_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>[few200_hidden256_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_hidden128_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few200_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>[full_hidden256_vocab16000.txt, full_hidden256...</td>\n      <td>[full_hidden512_vocab16000.txt, full_hidden512...</td>\n      <td>[full_fc512_lr0.0005_frozen.txt]</td>\n      <td>[full_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>[trg_hidden512_vocab16000.txt, trg_hidden512_v...</td>\n      <td>[trg_hidden128_vocab16000.txt, trg_hidden128_v...</td>\n      <td>[trg_fc256_lr0.005_frozen.txt]</td>\n      <td>[trg_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams_dfs_dict['aren']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ar-bg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x17d72d9fda0>",
      "text/html": "<style  type=\"text/css\" >\n#T_e8872c50_9883_11eb_acb7_a0cec835c16drow0_col4,#T_e8872c50_9883_11eb_acb7_a0cec835c16drow1_col4,#T_e8872c50_9883_11eb_acb7_a0cec835c16drow2_col4,#T_e8872c50_9883_11eb_acb7_a0cec835c16drow3_col4,#T_e8872c50_9883_11eb_acb7_a0cec835c16drow4_col3,#T_e8872c50_9883_11eb_acb7_a0cec835c16drow5_col4,#T_e8872c50_9883_11eb_acb7_a0cec835c16drow6_col4{\n            background:  red;\n        }</style><table id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Setup</th>        <th class=\"col_heading level0 col1\" >logistic_regression</th>        <th class=\"col_heading level0 col2\" >transformer_encoder</th>        <th class=\"col_heading level0 col3\" >bert-base-uncased</th>        <th class=\"col_heading level0 col4\" >bert-base-multilingual-cased</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow0_col0\" class=\"data row0 col0\" >zero</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow0_col1\" class=\"data row0 col1\" >0.558355</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow0_col2\" class=\"data row0 col2\" >0.805075</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow0_col3\" class=\"data row0 col3\" >0.802720</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow0_col4\" class=\"data row0 col4\" >0.808254</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow1_col0\" class=\"data row1 col0\" >few50</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow1_col1\" class=\"data row1 col1\" >0.794193</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow1_col2\" class=\"data row1 col2\" >0.803829</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow1_col3\" class=\"data row1 col3\" >0.810778</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow1_col4\" class=\"data row1 col4\" >0.815238</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow2_col0\" class=\"data row2 col0\" >few100</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow2_col1\" class=\"data row2 col1\" >0.799189</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow2_col2\" class=\"data row2 col2\" >0.808224</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow2_col3\" class=\"data row2 col3\" >0.818481</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow2_col4\" class=\"data row2 col4\" >0.821288</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow3_col0\" class=\"data row3 col0\" >few150</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow3_col1\" class=\"data row3 col1\" >0.800414</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow3_col2\" class=\"data row3 col2\" >0.816061</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow3_col3\" class=\"data row3 col3\" >0.819586</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow3_col4\" class=\"data row3 col4\" >0.820654</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow4_col0\" class=\"data row4 col0\" >few200</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow4_col1\" class=\"data row4 col1\" >0.800421</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow4_col2\" class=\"data row4 col2\" >0.811238</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow4_col3\" class=\"data row4 col3\" >0.822103</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow4_col4\" class=\"data row4 col4\" >0.819945</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow5_col0\" class=\"data row5 col0\" >full</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow5_col1\" class=\"data row5 col1\" >0.820994</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow5_col2\" class=\"data row5 col2\" >0.812141</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow5_col3\" class=\"data row5 col3\" >0.821548</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow5_col4\" class=\"data row5 col4\" >0.836257</td>\n            </tr>\n            <tr>\n                        <th id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow6_col0\" class=\"data row6 col0\" >trg</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow6_col1\" class=\"data row6 col1\" >0.813775</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow6_col2\" class=\"data row6 col2\" >0.809617</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow6_col3\" class=\"data row6 col3\" >0.821763</td>\n                        <td id=\"T_e8872c50_9883_11eb_acb7_a0cec835c16drow6_col4\" class=\"data row6 col4\" >0.843117</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_best_score(best_results_dfs_dict['arbg'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Setup   |   logistic_regression |   transformer_encoder | bert-base-uncased   | bert-base-multilingual-cased   |\n",
      "|---------|-----------------------|-----------------------|---------------------|--------------------------------|\n",
      "| zero    |                0.5584 |                0.8051 | 0.8027              | **0.8083**                     |\n",
      "| few50   |                0.7942 |                0.8038 | 0.8108              | **0.8152**                     |\n",
      "| few100  |                0.7992 |                0.8082 | 0.8185              | **0.8213**                     |\n",
      "| few150  |                0.8004 |                0.8161 | 0.8196              | **0.8207**                     |\n",
      "| few200  |                0.8004 |                0.8112 | **0.8221**          | 0.8199                         |\n",
      "| full    |                0.821  |                0.8121 | 0.8215              | **0.8363**                     |\n",
      "| trg     |                0.8138 |                0.8096 | 0.8218              | **0.8431**                     |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_markdown(best_results_dfs_dict['arbg']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\hline\n",
      " Setup   &   logistic\\_regression &   transformer\\_encoder &   bert-base-uncased &   bert-base-multilingual-cased \\\\\n",
      "\\hline\n",
      " zero    &                0.5584 &                0.8051 &              0.8027 &                         0.8083 \\\\\n",
      " few50   &                0.7942 &                0.8038 &              0.8108 &                         0.8152 \\\\\n",
      " few100  &                0.7992 &                0.8082 &              0.8185 &                         0.8213 \\\\\n",
      " few150  &                0.8004 &                0.8161 &              0.8196 &                         0.8207 \\\\\n",
      " few200  &                0.8004 &                0.8112 &              0.8221 &                         0.8199 \\\\\n",
      " full    &                0.821  &                0.8121 &              0.8215 &                         0.8363 \\\\\n",
      " trg     &                0.8138 &                0.8096 &              0.8218 &                         0.8431 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_latex(best_results_dfs_dict['arbg']))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup                                logistic_regression  \\\n0    zero  [zero_hidden128_vocab16000.txt, zero_hidden128...   \n1   few50  [few50_hidden256_vocab16000.txt, few50_hidden2...   \n2  few100  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  few150  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  few200  [few200_hidden512_vocab16000.txt, few200_hidde...   \n5    full  [full_hidden256_vocab16000.txt, full_hidden256...   \n6     trg  [trg_hidden256_vocab16000.txt, trg_hidden256_v...   \n\n                                 transformer_encoder  \\\n0  [zero_hidden512_vocab16000.txt, zero_hidden512...   \n1  [few50_hidden256_vocab16000.txt, few50_hidden2...   \n2  [few100_hidden256_vocab16000.txt, few100_hidde...   \n3  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  [few200_hidden512_vocab16000.txt, few200_hidde...   \n5  [full_hidden128_vocab16000.txt, full_hidden128...   \n6  [trg_hidden256_vocab16000.txt, trg_hidden256_v...   \n\n                                   bert-base-uncased  \\\n0  [zero_fc128_lr0.0005_trainable.txt, zero_fc128...   \n1                  [few50_fc128_lr0.0005_frozen.txt]   \n2                 [few100_fc128_lr0.0005_frozen.txt]   \n3                 [few150_fc128_lr0.0005_frozen.txt]   \n4                  [few200_fc256_lr0.005_frozen.txt]   \n5                   [full_fc256_lr0.0005_frozen.txt]   \n6                    [trg_fc128_lr0.0005_frozen.txt]   \n\n         bert-base-multilingual-cased  \n0     [zero_fc256_lr0.005_frozen.txt]  \n1   [few50_fc512_lr0.0005_frozen.txt]  \n2   [few100_fc128_lr0.005_frozen.txt]  \n3  [few150_fc256_lr0.0005_frozen.txt]  \n4  [few200_fc128_lr0.0005_frozen.txt]  \n5    [full_fc512_lr0.0005_frozen.txt]  \n6     [trg_fc512_lr0.0005_frozen.txt]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>[zero_hidden128_vocab16000.txt, zero_hidden128...</td>\n      <td>[zero_hidden512_vocab16000.txt, zero_hidden512...</td>\n      <td>[zero_fc128_lr0.0005_trainable.txt, zero_fc128...</td>\n      <td>[zero_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>[few50_hidden256_vocab16000.txt, few50_hidden2...</td>\n      <td>[few50_hidden256_vocab16000.txt, few50_hidden2...</td>\n      <td>[few50_fc128_lr0.0005_frozen.txt]</td>\n      <td>[few50_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_hidden256_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_fc128_lr0.0005_frozen.txt]</td>\n      <td>[few100_fc128_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_fc128_lr0.0005_frozen.txt]</td>\n      <td>[few150_fc256_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>[few200_hidden512_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_hidden512_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_fc256_lr0.005_frozen.txt]</td>\n      <td>[few200_fc128_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>[full_hidden256_vocab16000.txt, full_hidden256...</td>\n      <td>[full_hidden128_vocab16000.txt, full_hidden128...</td>\n      <td>[full_fc256_lr0.0005_frozen.txt]</td>\n      <td>[full_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>[trg_hidden256_vocab16000.txt, trg_hidden256_v...</td>\n      <td>[trg_hidden256_vocab16000.txt, trg_hidden256_v...</td>\n      <td>[trg_fc128_lr0.0005_frozen.txt]</td>\n      <td>[trg_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams_dfs_dict['arbg']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}