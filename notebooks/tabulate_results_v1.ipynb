{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tabulate results\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "sys.path.append('../src')\n",
    "from read_log_file import read_log_file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "LOG_HOME_DIR = os.path.join('../logs_v1/')\n",
    "assert os.path.isdir(LOG_HOME_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "MODEL_NAMES = ['logistic_regression', 'transformer_encoder', 'bert-base-uncased', 'bert-base-multilingual-cased']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "SETUPS = ['zero', 'few50', 'few100', 'few150', 'few200', 'full', 'trg']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_best_score_from_dict(di: dict) -> dict:\n",
    "    \"\"\"Get max value from a dict\"\"\"\n",
    "    keys_with_max_val = []\n",
    "    # find max value\n",
    "    max_val = -float('inf')\n",
    "    for k, v in di.items():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "    # find all keys with max value\n",
    "    for k, v in di.items():\n",
    "        if v == max_val:\n",
    "            keys_with_max_val.append(k)\n",
    "    return {\n",
    "        'k': keys_with_max_val,\n",
    "        'v': max_val,\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def create_best_results_df(langs: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    results_dict = {}\n",
    "    for model_name in MODEL_NAMES:\n",
    "        results_dict[model_name] = {}\n",
    "        log_dir = os.path.join(LOG_HOME_DIR, langs, model_name)\n",
    "        log_filenames = os.listdir(log_dir)\n",
    "        for fname in log_filenames:\n",
    "            results_dict[model_name][fname] = read_log_file(\n",
    "                log_file_path=os.path.join(log_dir, fname),\n",
    "                plot=False,\n",
    "                verbose=False,\n",
    "            )['best_val_metrics']['f1']\n",
    "\n",
    "    best_results_dict = {'Setup': SETUPS}\n",
    "    best_hparams_dict = {'Setup': SETUPS}\n",
    "    best_results_dict.update({model_name: [] for model_name in MODEL_NAMES})\n",
    "    best_hparams_dict.update({model_name: [] for model_name in MODEL_NAMES})\n",
    "    for model_name in MODEL_NAMES:\n",
    "        for setup in SETUPS:\n",
    "            best_score = get_best_score_from_dict(\n",
    "                {k: v for k, v in results_dict[model_name].items() if k.startswith(f'{setup}_')}\n",
    "            )\n",
    "            best_results_dict[model_name].append(\n",
    "                best_score['v']\n",
    "            )\n",
    "            best_hparams_dict[model_name].append(\n",
    "                best_score['k']\n",
    "            )\n",
    "\n",
    "\n",
    "    best_results_df = pd.DataFrame(best_results_dict)\n",
    "    best_hparams_df = pd.DataFrame(best_hparams_dict)\n",
    "    return best_results_df, best_hparams_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def highlight_best_score(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Highlight best score in each row\"\"\"\n",
    "    return df.style.apply(lambda x: ['background: red' if isinstance(v, float) and v == max(x.iloc[1:]) else '' for v in x], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def tabulate_markdown(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Tabulate in markdown format and bold best scores in each row\"\"\"\n",
    "    df = df.round(4)\n",
    "    for model_name in MODEL_NAMES:\n",
    "        df[model_name] = df[model_name].astype(str)\n",
    "    for idx in range(len(df)):\n",
    "        max_val = max(float(df.iloc[idx][model_name]) for model_name in MODEL_NAMES)\n",
    "        for model_name in MODEL_NAMES:\n",
    "            cell_val = float(df.iloc[idx][model_name])\n",
    "            if cell_val == max_val:\n",
    "                df.at[idx, model_name] = f'**{cell_val}**'\n",
    "            else:\n",
    "                df.at[idx, model_name] = f'{cell_val}'\n",
    "\n",
    "    return tabulate(df, headers='keys', showindex=False, tablefmt='github')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:19<00:00,  3.30s/it]\n"
     ]
    }
   ],
   "source": [
    "best_results_dfs_dict = {}\n",
    "best_hparams_dfs_dict = {}\n",
    "for langs in tqdm(['enbg', 'enar', 'bgen', 'bgar', 'aren', 'arbg']):\n",
    "    best_results_dfs_dict[langs], best_hparams_dfs_dict[langs] = create_best_results_df(langs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## en-bg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x2a2ad45c8d0>",
      "text/html": "<style  type=\"text/css\" >\n#T_7f13934a_9883_11eb_ac04_a0cec835c16drow0_col4,#T_7f13934a_9883_11eb_ac04_a0cec835c16drow1_col3,#T_7f13934a_9883_11eb_ac04_a0cec835c16drow2_col4,#T_7f13934a_9883_11eb_ac04_a0cec835c16drow3_col3,#T_7f13934a_9883_11eb_ac04_a0cec835c16drow4_col4,#T_7f13934a_9883_11eb_ac04_a0cec835c16drow5_col4,#T_7f13934a_9883_11eb_ac04_a0cec835c16drow6_col4{\n            background:  red;\n        }</style><table id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Setup</th>        <th class=\"col_heading level0 col1\" >logistic_regression</th>        <th class=\"col_heading level0 col2\" >transformer_encoder</th>        <th class=\"col_heading level0 col3\" >bert-base-uncased</th>        <th class=\"col_heading level0 col4\" >bert-base-multilingual-cased</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow0_col0\" class=\"data row0 col0\" >zero</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow0_col1\" class=\"data row0 col1\" >0.508343</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow0_col2\" class=\"data row0 col2\" >0.791592</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow0_col3\" class=\"data row0 col3\" >0.803166</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow0_col4\" class=\"data row0 col4\" >0.804159</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow1_col0\" class=\"data row1 col0\" >few50</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow1_col1\" class=\"data row1 col1\" >0.669023</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow1_col2\" class=\"data row1 col2\" >0.805915</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow1_col3\" class=\"data row1 col3\" >0.811297</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow1_col4\" class=\"data row1 col4\" >0.810629</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow2_col0\" class=\"data row2 col0\" >few100</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow2_col1\" class=\"data row2 col1\" >0.789056</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow2_col2\" class=\"data row2 col2\" >0.808465</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow2_col3\" class=\"data row2 col3\" >0.812350</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow2_col4\" class=\"data row2 col4\" >0.815694</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow3_col0\" class=\"data row3 col0\" >few150</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow3_col1\" class=\"data row3 col1\" >0.801440</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow3_col2\" class=\"data row3 col2\" >0.812891</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow3_col3\" class=\"data row3 col3\" >0.820823</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow3_col4\" class=\"data row3 col4\" >0.815002</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow4_col0\" class=\"data row4 col0\" >few200</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow4_col1\" class=\"data row4 col1\" >0.806709</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow4_col2\" class=\"data row4 col2\" >0.811863</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow4_col3\" class=\"data row4 col3\" >0.813044</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow4_col4\" class=\"data row4 col4\" >0.816025</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow5_col0\" class=\"data row5 col0\" >full</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow5_col1\" class=\"data row5 col1\" >0.817149</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow5_col2\" class=\"data row5 col2\" >0.812225</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow5_col3\" class=\"data row5 col3\" >0.819922</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow5_col4\" class=\"data row5 col4\" >0.826783</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow6_col0\" class=\"data row6 col0\" >trg</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow6_col1\" class=\"data row6 col1\" >0.813775</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow6_col2\" class=\"data row6 col2\" >0.809617</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow6_col3\" class=\"data row6 col3\" >0.820598</td>\n                        <td id=\"T_7f13934a_9883_11eb_ac04_a0cec835c16drow6_col4\" class=\"data row6 col4\" >0.825151</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_best_score(best_results_dfs_dict['enbg'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Setup   |   logistic_regression |   transformer_encoder | bert-base-uncased   | bert-base-multilingual-cased   |\n",
      "|---------|-----------------------|-----------------------|---------------------|--------------------------------|\n",
      "| zero    |                0.5083 |                0.7916 | 0.8032              | **0.8042**                     |\n",
      "| few50   |                0.669  |                0.8059 | **0.8113**          | 0.8106                         |\n",
      "| few100  |                0.7891 |                0.8085 | 0.8123              | **0.8157**                     |\n",
      "| few150  |                0.8014 |                0.8129 | **0.8208**          | 0.815                          |\n",
      "| few200  |                0.8067 |                0.8119 | 0.813               | **0.816**                      |\n",
      "| full    |                0.8171 |                0.8122 | 0.8199              | **0.8268**                     |\n",
      "| trg     |                0.8138 |                0.8096 | 0.8206              | **0.8252**                     |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_markdown(best_results_dfs_dict['enbg']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup                                logistic_regression  \\\n0    zero  [zero_hidden128_vocab16000.txt, zero_hidden128...   \n1   few50  [few50_hidden256_vocab16000.txt, few50_hidden2...   \n2  few100  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  few150  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  few200  [few200_hidden256_vocab16000.txt, few200_hidde...   \n5    full  [full_hidden256_vocab16000.txt, full_hidden256...   \n6     trg  [trg_hidden256_vocab16000.txt, trg_hidden256_v...   \n\n                                 transformer_encoder  \\\n0  [zero_hidden512_vocab16000.txt, zero_hidden512...   \n1  [few50_hidden128_vocab16000.txt, few50_hidden1...   \n2  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  [few150_hidden256_vocab16000.txt, few150_hidde...   \n4  [few200_hidden128_vocab16000.txt, few200_hidde...   \n5  [full_hidden128_vocab16000.txt, full_hidden128...   \n6  [trg_hidden256_vocab16000.txt, trg_hidden256_v...   \n\n                    bert-base-uncased        bert-base-multilingual-cased  \n0      [zero_fc512_lr0.05_frozen.txt]     [zero_fc512_lr0.005_frozen.txt]  \n1   [few50_fc512_lr0.0005_frozen.txt]   [few50_fc512_lr0.0005_frozen.txt]  \n2  [few100_fc256_lr0.0005_frozen.txt]  [few100_fc512_lr0.0005_frozen.txt]  \n3   [few150_fc512_lr0.005_frozen.txt]   [few150_fc512_lr0.005_frozen.txt]  \n4  [few200_fc512_lr0.0005_frozen.txt]   [few200_fc256_lr0.005_frozen.txt]  \n5     [full_fc128_lr0.005_frozen.txt]    [full_fc128_lr0.0005_frozen.txt]  \n6      [trg_fc512_lr0.005_frozen.txt]      [trg_fc256_lr0.005_frozen.txt]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>[zero_hidden128_vocab16000.txt, zero_hidden128...</td>\n      <td>[zero_hidden512_vocab16000.txt, zero_hidden512...</td>\n      <td>[zero_fc512_lr0.05_frozen.txt]</td>\n      <td>[zero_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>[few50_hidden256_vocab16000.txt, few50_hidden2...</td>\n      <td>[few50_hidden128_vocab16000.txt, few50_hidden1...</td>\n      <td>[few50_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few50_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_fc256_lr0.0005_frozen.txt]</td>\n      <td>[few100_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_hidden256_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_fc512_lr0.005_frozen.txt]</td>\n      <td>[few150_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>[few200_hidden256_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_hidden128_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few200_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>[full_hidden256_vocab16000.txt, full_hidden256...</td>\n      <td>[full_hidden128_vocab16000.txt, full_hidden128...</td>\n      <td>[full_fc128_lr0.005_frozen.txt]</td>\n      <td>[full_fc128_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>[trg_hidden256_vocab16000.txt, trg_hidden256_v...</td>\n      <td>[trg_hidden256_vocab16000.txt, trg_hidden256_v...</td>\n      <td>[trg_fc512_lr0.005_frozen.txt]</td>\n      <td>[trg_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams_dfs_dict['enbg']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## en-ar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x2a2ad7f9e48>",
      "text/html": "<style  type=\"text/css\" >\n#T_7f236c7e_9883_11eb_beef_a0cec835c16drow0_col4,#T_7f236c7e_9883_11eb_beef_a0cec835c16drow1_col4,#T_7f236c7e_9883_11eb_beef_a0cec835c16drow2_col4,#T_7f236c7e_9883_11eb_beef_a0cec835c16drow3_col4,#T_7f236c7e_9883_11eb_beef_a0cec835c16drow4_col2,#T_7f236c7e_9883_11eb_beef_a0cec835c16drow5_col2,#T_7f236c7e_9883_11eb_beef_a0cec835c16drow6_col4{\n            background:  red;\n        }</style><table id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Setup</th>        <th class=\"col_heading level0 col1\" >logistic_regression</th>        <th class=\"col_heading level0 col2\" >transformer_encoder</th>        <th class=\"col_heading level0 col3\" >bert-base-uncased</th>        <th class=\"col_heading level0 col4\" >bert-base-multilingual-cased</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow0_col0\" class=\"data row0 col0\" >zero</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow0_col1\" class=\"data row0 col1\" >0.459554</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow0_col2\" class=\"data row0 col2\" >0.543634</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow0_col3\" class=\"data row0 col3\" >0.541674</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow0_col4\" class=\"data row0 col4\" >0.626963</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow1_col0\" class=\"data row1 col0\" >few50</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow1_col1\" class=\"data row1 col1\" >0.602569</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow1_col2\" class=\"data row1 col2\" >0.628380</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow1_col3\" class=\"data row1 col3\" >0.588368</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow1_col4\" class=\"data row1 col4\" >0.640045</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow2_col0\" class=\"data row2 col0\" >few100</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow2_col1\" class=\"data row2 col1\" >0.599670</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow2_col2\" class=\"data row2 col2\" >0.655968</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow2_col3\" class=\"data row2 col3\" >0.631603</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow2_col4\" class=\"data row2 col4\" >0.699871</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow3_col0\" class=\"data row3 col0\" >few150</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow3_col1\" class=\"data row3 col1\" >0.620090</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow3_col2\" class=\"data row3 col2\" >0.708560</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow3_col3\" class=\"data row3 col3\" >0.655699</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow3_col4\" class=\"data row3 col4\" >0.727245</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow4_col0\" class=\"data row4 col0\" >few200</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow4_col1\" class=\"data row4 col1\" >0.622177</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow4_col2\" class=\"data row4 col2\" >0.714131</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow4_col3\" class=\"data row4 col3\" >0.580542</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow4_col4\" class=\"data row4 col4\" >0.706095</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow5_col0\" class=\"data row5 col0\" >full</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow5_col1\" class=\"data row5 col1\" >0.622177</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow5_col2\" class=\"data row5 col2\" >0.714131</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow5_col3\" class=\"data row5 col3\" >0.580542</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow5_col4\" class=\"data row5 col4\" >0.706095</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow6_col0\" class=\"data row6 col0\" >trg</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow6_col1\" class=\"data row6 col1\" >0.644527</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow6_col2\" class=\"data row6 col2\" >0.695322</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow6_col3\" class=\"data row6 col3\" >0.581654</td>\n                        <td id=\"T_7f236c7e_9883_11eb_beef_a0cec835c16drow6_col4\" class=\"data row6 col4\" >0.712644</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_best_score(best_results_dfs_dict['enar'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Setup   |   logistic_regression | transformer_encoder   |   bert-base-uncased | bert-base-multilingual-cased   |\n",
      "|---------|-----------------------|-----------------------|---------------------|--------------------------------|\n",
      "| zero    |                0.4596 | 0.5436                |              0.5417 | **0.627**                      |\n",
      "| few50   |                0.6026 | 0.6284                |              0.5884 | **0.64**                       |\n",
      "| few100  |                0.5997 | 0.656                 |              0.6316 | **0.6999**                     |\n",
      "| few150  |                0.6201 | 0.7086                |              0.6557 | **0.7272**                     |\n",
      "| few200  |                0.6222 | **0.7141**            |              0.5805 | 0.7061                         |\n",
      "| full    |                0.6222 | **0.7141**            |              0.5805 | 0.7061                         |\n",
      "| trg     |                0.6445 | 0.6953                |              0.5817 | **0.7126**                     |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_markdown(best_results_dfs_dict['enar']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup                                logistic_regression  \\\n0    zero  [zero_hidden128_vocab16000.txt, zero_hidden128...   \n1   few50  [few50_hidden256_vocab16000.txt, few50_hidden2...   \n2  few100  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  few150  [few150_hidden256_vocab16000.txt, few150_hidde...   \n4  few200  [few200_hidden128_vocab16000.txt, few200_hidde...   \n5    full  [full_hidden128_vocab16000.txt, full_hidden128...   \n6     trg  [trg_hidden512_vocab16000.txt, trg_hidden512_v...   \n\n                                 transformer_encoder  \\\n0  [zero_hidden256_vocab16000.txt, zero_hidden256...   \n1  [few50_hidden512_vocab16000.txt, few50_hidden5...   \n2  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  [few150_hidden128_vocab16000.txt, few150_hidde...   \n4  [few200_hidden512_vocab16000.txt, few200_hidde...   \n5  [full_hidden512_vocab16000.txt, full_hidden512...   \n6  [trg_hidden128_vocab16000.txt, trg_hidden128_v...   \n\n                    bert-base-uncased        bert-base-multilingual-cased  \n0    [zero_fc256_lr0.0005_frozen.txt]     [zero_fc512_lr0.005_frozen.txt]  \n1   [few50_fc512_lr0.0005_frozen.txt]    [few50_fc128_lr0.005_frozen.txt]  \n2   [few100_fc128_lr0.005_frozen.txt]   [few100_fc128_lr0.005_frozen.txt]  \n3   [few150_fc512_lr0.005_frozen.txt]  [few150_fc512_lr0.0005_frozen.txt]  \n4  [few200_fc512_lr0.0005_frozen.txt]  [few200_fc512_lr0.0005_frozen.txt]  \n5    [full_fc512_lr0.0005_frozen.txt]    [full_fc512_lr0.0005_frozen.txt]  \n6      [trg_fc512_lr0.005_frozen.txt]      [trg_fc256_lr0.005_frozen.txt]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>[zero_hidden128_vocab16000.txt, zero_hidden128...</td>\n      <td>[zero_hidden256_vocab16000.txt, zero_hidden256...</td>\n      <td>[zero_fc256_lr0.0005_frozen.txt]</td>\n      <td>[zero_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>[few50_hidden256_vocab16000.txt, few50_hidden2...</td>\n      <td>[few50_hidden512_vocab16000.txt, few50_hidden5...</td>\n      <td>[few50_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few50_fc128_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_fc128_lr0.005_frozen.txt]</td>\n      <td>[few100_fc128_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>[few150_hidden256_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_hidden128_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_fc512_lr0.005_frozen.txt]</td>\n      <td>[few150_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>[few200_hidden128_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_hidden512_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few200_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>[full_hidden128_vocab16000.txt, full_hidden128...</td>\n      <td>[full_hidden512_vocab16000.txt, full_hidden512...</td>\n      <td>[full_fc512_lr0.0005_frozen.txt]</td>\n      <td>[full_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>[trg_hidden512_vocab16000.txt, trg_hidden512_v...</td>\n      <td>[trg_hidden128_vocab16000.txt, trg_hidden128_v...</td>\n      <td>[trg_fc512_lr0.005_frozen.txt]</td>\n      <td>[trg_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams_dfs_dict['enar']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bg-en"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x2a2ad86fd68>",
      "text/html": "<style  type=\"text/css\" >\n#T_7f32b81a_9883_11eb_8184_a0cec835c16drow0_col2,#T_7f32b81a_9883_11eb_8184_a0cec835c16drow1_col2,#T_7f32b81a_9883_11eb_8184_a0cec835c16drow2_col4,#T_7f32b81a_9883_11eb_8184_a0cec835c16drow3_col4,#T_7f32b81a_9883_11eb_8184_a0cec835c16drow4_col4,#T_7f32b81a_9883_11eb_8184_a0cec835c16drow5_col3,#T_7f32b81a_9883_11eb_8184_a0cec835c16drow6_col3{\n            background:  red;\n        }</style><table id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Setup</th>        <th class=\"col_heading level0 col1\" >logistic_regression</th>        <th class=\"col_heading level0 col2\" >transformer_encoder</th>        <th class=\"col_heading level0 col3\" >bert-base-uncased</th>        <th class=\"col_heading level0 col4\" >bert-base-multilingual-cased</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow0_col0\" class=\"data row0 col0\" >zero</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow0_col1\" class=\"data row0 col1\" >0.439126</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow0_col2\" class=\"data row0 col2\" >0.528149</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow0_col3\" class=\"data row0 col3\" >0.476081</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow0_col4\" class=\"data row0 col4\" >0.508174</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow1_col0\" class=\"data row1 col0\" >few50</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow1_col1\" class=\"data row1 col1\" >0.587053</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow1_col2\" class=\"data row1 col2\" >0.605046</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow1_col3\" class=\"data row1 col3\" >0.604485</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow1_col4\" class=\"data row1 col4\" >0.595866</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow2_col0\" class=\"data row2 col0\" >few100</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow2_col1\" class=\"data row2 col1\" >0.590057</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow2_col2\" class=\"data row2 col2\" >0.600062</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow2_col3\" class=\"data row2 col3\" >0.633917</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow2_col4\" class=\"data row2 col4\" >0.648412</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow3_col0\" class=\"data row3 col0\" >few150</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow3_col1\" class=\"data row3 col1\" >0.592898</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow3_col2\" class=\"data row3 col2\" >0.594378</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow3_col3\" class=\"data row3 col3\" >0.639445</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow3_col4\" class=\"data row3 col4\" >0.648841</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow4_col0\" class=\"data row4 col0\" >few200</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow4_col1\" class=\"data row4 col1\" >0.592521</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow4_col2\" class=\"data row4 col2\" >0.599739</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow4_col3\" class=\"data row4 col3\" >0.647169</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow4_col4\" class=\"data row4 col4\" >0.659728</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow5_col0\" class=\"data row5 col0\" >full</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow5_col1\" class=\"data row5 col1\" >0.589093</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow5_col2\" class=\"data row5 col2\" >0.616020</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow5_col3\" class=\"data row5 col3\" >0.682836</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow5_col4\" class=\"data row5 col4\" >0.670561</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow6_col0\" class=\"data row6 col0\" >trg</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow6_col1\" class=\"data row6 col1\" >0.568931</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow6_col2\" class=\"data row6 col2\" >0.624487</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow6_col3\" class=\"data row6 col3\" >0.677584</td>\n                        <td id=\"T_7f32b81a_9883_11eb_8184_a0cec835c16drow6_col4\" class=\"data row6 col4\" >0.649745</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_best_score(best_results_dfs_dict['bgen'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Setup   |   logistic_regression | transformer_encoder   | bert-base-uncased   | bert-base-multilingual-cased   |\n",
      "|---------|-----------------------|-----------------------|---------------------|--------------------------------|\n",
      "| zero    |                0.4391 | **0.5281**            | 0.4761              | 0.5082                         |\n",
      "| few50   |                0.5871 | **0.605**             | 0.6045              | 0.5959                         |\n",
      "| few100  |                0.5901 | 0.6001                | 0.6339              | **0.6484**                     |\n",
      "| few150  |                0.5929 | 0.5944                | 0.6394              | **0.6488**                     |\n",
      "| few200  |                0.5925 | 0.5997                | 0.6472              | **0.6597**                     |\n",
      "| full    |                0.5891 | 0.616                 | **0.6828**          | 0.6706                         |\n",
      "| trg     |                0.5689 | 0.6245                | **0.6776**          | 0.6497                         |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_markdown(best_results_dfs_dict['bgen']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup                                logistic_regression  \\\n0    zero  [zero_hidden128_vocab16000.txt, zero_hidden128...   \n1   few50  [few50_hidden128_vocab16000.txt, few50_hidden1...   \n2  few100  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  few150  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  few200  [few200_hidden256_vocab16000.txt, few200_hidde...   \n5    full  [full_hidden128_vocab16000.txt, full_hidden128...   \n6     trg  [trg_hidden512_vocab16000.txt, trg_hidden512_v...   \n\n                                 transformer_encoder  \\\n0  [zero_hidden256_vocab16000.txt, zero_hidden256...   \n1  [few50_hidden512_vocab16000.txt, few50_hidden5...   \n2  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  [few200_hidden256_vocab16000.txt, few200_hidde...   \n5  [full_hidden256_vocab16000.txt, full_hidden256...   \n6  [trg_hidden512_vocab16000.txt, trg_hidden512_v...   \n\n                    bert-base-uncased       bert-base-multilingual-cased  \n0      [zero_fc256_lr0.05_frozen.txt]     [zero_fc512_lr0.05_frozen.txt]  \n1   [few50_fc128_lr0.0005_frozen.txt]  [few50_fc512_lr0.0005_frozen.txt]  \n2   [few100_fc512_lr0.005_frozen.txt]  [few100_fc128_lr0.005_frozen.txt]  \n3  [few150_fc512_lr0.0005_frozen.txt]  [few150_fc256_lr0.005_frozen.txt]  \n4  [few200_fc512_lr0.0005_frozen.txt]  [few200_fc256_lr0.005_frozen.txt]  \n5     [full_fc128_lr0.005_frozen.txt]    [full_fc512_lr0.005_frozen.txt]  \n6      [trg_fc512_lr0.005_frozen.txt]     [trg_fc512_lr0.005_frozen.txt]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>[zero_hidden128_vocab16000.txt, zero_hidden128...</td>\n      <td>[zero_hidden256_vocab16000.txt, zero_hidden256...</td>\n      <td>[zero_fc256_lr0.05_frozen.txt]</td>\n      <td>[zero_fc512_lr0.05_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>[few50_hidden128_vocab16000.txt, few50_hidden1...</td>\n      <td>[few50_hidden512_vocab16000.txt, few50_hidden5...</td>\n      <td>[few50_fc128_lr0.0005_frozen.txt]</td>\n      <td>[few50_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_fc512_lr0.005_frozen.txt]</td>\n      <td>[few100_fc128_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few150_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>[few200_hidden256_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_hidden256_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few200_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>[full_hidden128_vocab16000.txt, full_hidden128...</td>\n      <td>[full_hidden256_vocab16000.txt, full_hidden256...</td>\n      <td>[full_fc128_lr0.005_frozen.txt]</td>\n      <td>[full_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>[trg_hidden512_vocab16000.txt, trg_hidden512_v...</td>\n      <td>[trg_hidden512_vocab16000.txt, trg_hidden512_v...</td>\n      <td>[trg_fc512_lr0.005_frozen.txt]</td>\n      <td>[trg_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams_dfs_dict['bgen']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## bg-ar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x2a2ad880588>",
      "text/html": "<style  type=\"text/css\" >\n#T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow0_col2,#T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow1_col2,#T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow2_col4,#T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow3_col4,#T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow4_col2,#T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow5_col2,#T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow6_col4{\n            background:  red;\n        }</style><table id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Setup</th>        <th class=\"col_heading level0 col1\" >logistic_regression</th>        <th class=\"col_heading level0 col2\" >transformer_encoder</th>        <th class=\"col_heading level0 col3\" >bert-base-uncased</th>        <th class=\"col_heading level0 col4\" >bert-base-multilingual-cased</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow0_col0\" class=\"data row0 col0\" >zero</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow0_col1\" class=\"data row0 col1\" >0.496158</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow0_col2\" class=\"data row0 col2\" >0.583020</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow0_col3\" class=\"data row0 col3\" >0.518447</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow0_col4\" class=\"data row0 col4\" >0.577075</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow1_col0\" class=\"data row1 col0\" >few50</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow1_col1\" class=\"data row1 col1\" >0.565675</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow1_col2\" class=\"data row1 col2\" >0.674656</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow1_col3\" class=\"data row1 col3\" >0.557078</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow1_col4\" class=\"data row1 col4\" >0.606410</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow2_col0\" class=\"data row2 col0\" >few100</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow2_col1\" class=\"data row2 col1\" >0.645268</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow2_col2\" class=\"data row2 col2\" >0.646060</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow2_col3\" class=\"data row2 col3\" >0.654343</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow2_col4\" class=\"data row2 col4\" >0.666635</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow3_col0\" class=\"data row3 col0\" >few150</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow3_col1\" class=\"data row3 col1\" >0.642236</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow3_col2\" class=\"data row3 col2\" >0.688185</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow3_col3\" class=\"data row3 col3\" >0.602460</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow3_col4\" class=\"data row3 col4\" >0.698114</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow4_col0\" class=\"data row4 col0\" >few200</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow4_col1\" class=\"data row4 col1\" >0.654307</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow4_col2\" class=\"data row4 col2\" >0.709412</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow4_col3\" class=\"data row4 col3\" >0.608944</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow4_col4\" class=\"data row4 col4\" >0.676088</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow5_col0\" class=\"data row5 col0\" >full</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow5_col1\" class=\"data row5 col1\" >0.654307</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow5_col2\" class=\"data row5 col2\" >0.709412</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow5_col3\" class=\"data row5 col3\" >0.608944</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow5_col4\" class=\"data row5 col4\" >0.676088</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow6_col0\" class=\"data row6 col0\" >trg</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow6_col1\" class=\"data row6 col1\" >0.480602</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow6_col2\" class=\"data row6 col2\" >0.664462</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow6_col3\" class=\"data row6 col3\" >0.581654</td>\n                        <td id=\"T_7f41f40a_9883_11eb_8fbd_a0cec835c16drow6_col4\" class=\"data row6 col4\" >0.712644</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_best_score(best_results_dfs_dict['bgar'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Setup   |   logistic_regression | transformer_encoder   |   bert-base-uncased | bert-base-multilingual-cased   |\n",
      "|---------|-----------------------|-----------------------|---------------------|--------------------------------|\n",
      "| zero    |                0.4962 | **0.583**             |              0.5184 | 0.5771                         |\n",
      "| few50   |                0.5657 | **0.6747**            |              0.5571 | 0.6064                         |\n",
      "| few100  |                0.6453 | 0.6461                |              0.6543 | **0.6666**                     |\n",
      "| few150  |                0.6422 | 0.6882                |              0.6025 | **0.6981**                     |\n",
      "| few200  |                0.6543 | **0.7094**            |              0.6089 | 0.6761                         |\n",
      "| full    |                0.6543 | **0.7094**            |              0.6089 | 0.6761                         |\n",
      "| trg     |                0.4806 | 0.6645                |              0.5817 | **0.7126**                     |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_markdown(best_results_dfs_dict['bgar']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup                                logistic_regression  \\\n0    zero  [zero_hidden128_vocab16000.txt, zero_hidden128...   \n1   few50  [few50_hidden512_vocab16000.txt, few50_hidden5...   \n2  few100  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  few150  [few150_hidden256_vocab16000.txt, few150_hidde...   \n4  few200  [few200_hidden256_vocab16000.txt, few200_hidde...   \n5    full  [full_hidden256_vocab16000.txt, full_hidden256...   \n6     trg  [trg_hidden512_vocab16000.txt, trg_hidden512_v...   \n\n                                 transformer_encoder  \\\n0  [zero_hidden256_vocab16000.txt, zero_hidden256...   \n1  [few50_hidden256_vocab16000.txt, few50_hidden2...   \n2  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  [few150_hidden128_vocab16000.txt, few150_hidde...   \n4  [few200_hidden256_vocab16000.txt, few200_hidde...   \n5  [full_hidden256_vocab16000.txt, full_hidden256...   \n6  [trg_hidden128_vocab16000.txt, trg_hidden128_v...   \n\n                                   bert-base-uncased  \\\n0  [zero_fc128_lr0.0005_trainable.txt, zero_fc128...   \n1                   [few50_fc512_lr0.005_frozen.txt]   \n2                 [few100_fc512_lr0.0005_frozen.txt]   \n3                 [few150_fc512_lr0.0005_frozen.txt]   \n4                 [few200_fc256_lr0.0005_frozen.txt]   \n5                   [full_fc256_lr0.0005_frozen.txt]   \n6                     [trg_fc512_lr0.005_frozen.txt]   \n\n         bert-base-multilingual-cased  \n0     [zero_fc128_lr0.005_frozen.txt]  \n1   [few50_fc256_lr0.0005_frozen.txt]  \n2  [few100_fc512_lr0.0005_frozen.txt]  \n3  [few150_fc512_lr0.0005_frozen.txt]  \n4  [few200_fc512_lr0.0005_frozen.txt]  \n5    [full_fc512_lr0.0005_frozen.txt]  \n6      [trg_fc256_lr0.005_frozen.txt]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>[zero_hidden128_vocab16000.txt, zero_hidden128...</td>\n      <td>[zero_hidden256_vocab16000.txt, zero_hidden256...</td>\n      <td>[zero_fc128_lr0.0005_trainable.txt, zero_fc128...</td>\n      <td>[zero_fc128_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>[few50_hidden512_vocab16000.txt, few50_hidden5...</td>\n      <td>[few50_hidden256_vocab16000.txt, few50_hidden2...</td>\n      <td>[few50_fc512_lr0.005_frozen.txt]</td>\n      <td>[few50_fc256_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few100_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>[few150_hidden256_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_hidden128_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few150_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>[few200_hidden256_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_hidden256_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_fc256_lr0.0005_frozen.txt]</td>\n      <td>[few200_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>[full_hidden256_vocab16000.txt, full_hidden256...</td>\n      <td>[full_hidden256_vocab16000.txt, full_hidden256...</td>\n      <td>[full_fc256_lr0.0005_frozen.txt]</td>\n      <td>[full_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>[trg_hidden512_vocab16000.txt, trg_hidden512_v...</td>\n      <td>[trg_hidden128_vocab16000.txt, trg_hidden128_v...</td>\n      <td>[trg_fc512_lr0.005_frozen.txt]</td>\n      <td>[trg_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams_dfs_dict['bgar']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ar-en"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x2a2ad86fe80>",
      "text/html": "<style  type=\"text/css\" >\n#T_7f509de2_9883_11eb_8ac9_a0cec835c16drow0_col4,#T_7f509de2_9883_11eb_8ac9_a0cec835c16drow1_col3,#T_7f509de2_9883_11eb_8ac9_a0cec835c16drow2_col3,#T_7f509de2_9883_11eb_8ac9_a0cec835c16drow3_col3,#T_7f509de2_9883_11eb_8ac9_a0cec835c16drow4_col4,#T_7f509de2_9883_11eb_8ac9_a0cec835c16drow5_col4,#T_7f509de2_9883_11eb_8ac9_a0cec835c16drow6_col3{\n            background:  red;\n        }</style><table id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Setup</th>        <th class=\"col_heading level0 col1\" >logistic_regression</th>        <th class=\"col_heading level0 col2\" >transformer_encoder</th>        <th class=\"col_heading level0 col3\" >bert-base-uncased</th>        <th class=\"col_heading level0 col4\" >bert-base-multilingual-cased</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow0_col0\" class=\"data row0 col0\" >zero</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow0_col1\" class=\"data row0 col1\" >0.200949</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow0_col2\" class=\"data row0 col2\" >0.489936</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow0_col3\" class=\"data row0 col3\" >0.499624</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow0_col4\" class=\"data row0 col4\" >0.573033</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow1_col0\" class=\"data row1 col0\" >few50</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow1_col1\" class=\"data row1 col1\" >0.523237</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow1_col2\" class=\"data row1 col2\" >0.587793</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow1_col3\" class=\"data row1 col3\" >0.609163</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow1_col4\" class=\"data row1 col4\" >0.597817</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow2_col0\" class=\"data row2 col0\" >few100</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow2_col1\" class=\"data row2 col1\" >0.511002</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow2_col2\" class=\"data row2 col2\" >0.582618</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow2_col3\" class=\"data row2 col3\" >0.652872</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow2_col4\" class=\"data row2 col4\" >0.600951</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow3_col0\" class=\"data row3 col0\" >few150</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow3_col1\" class=\"data row3 col1\" >0.537679</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow3_col2\" class=\"data row3 col2\" >0.607381</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow3_col3\" class=\"data row3 col3\" >0.645421</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow3_col4\" class=\"data row3 col4\" >0.621036</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow4_col0\" class=\"data row4 col0\" >few200</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow4_col1\" class=\"data row4 col1\" >0.571547</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow4_col2\" class=\"data row4 col2\" >0.603234</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow4_col3\" class=\"data row4 col3\" >0.635513</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow4_col4\" class=\"data row4 col4\" >0.641816</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow5_col0\" class=\"data row5 col0\" >full</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow5_col1\" class=\"data row5 col1\" >0.565071</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow5_col2\" class=\"data row5 col2\" >0.589381</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow5_col3\" class=\"data row5 col3\" >0.664358</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow5_col4\" class=\"data row5 col4\" >0.681317</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow6_col0\" class=\"data row6 col0\" >trg</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow6_col1\" class=\"data row6 col1\" >0.568931</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow6_col2\" class=\"data row6 col2\" >0.624487</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow6_col3\" class=\"data row6 col3\" >0.677584</td>\n                        <td id=\"T_7f509de2_9883_11eb_8ac9_a0cec835c16drow6_col4\" class=\"data row6 col4\" >0.649745</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_best_score(best_results_dfs_dict['aren'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Setup   |   logistic_regression |   transformer_encoder | bert-base-uncased   | bert-base-multilingual-cased   |\n",
      "|---------|-----------------------|-----------------------|---------------------|--------------------------------|\n",
      "| zero    |                0.2009 |                0.4899 | 0.4996              | **0.573**                      |\n",
      "| few50   |                0.5232 |                0.5878 | **0.6092**          | 0.5978                         |\n",
      "| few100  |                0.511  |                0.5826 | **0.6529**          | 0.601                          |\n",
      "| few150  |                0.5377 |                0.6074 | **0.6454**          | 0.621                          |\n",
      "| few200  |                0.5715 |                0.6032 | 0.6355              | **0.6418**                     |\n",
      "| full    |                0.5651 |                0.5894 | 0.6644              | **0.6813**                     |\n",
      "| trg     |                0.5689 |                0.6245 | **0.6776**          | 0.6497                         |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_markdown(best_results_dfs_dict['aren']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup                                logistic_regression  \\\n0    zero  [zero_hidden128_vocab16000.txt, zero_hidden128...   \n1   few50  [few50_hidden256_vocab16000.txt, few50_hidden2...   \n2  few100  [few100_hidden256_vocab16000.txt, few100_hidde...   \n3  few150  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  few200  [few200_hidden512_vocab16000.txt, few200_hidde...   \n5    full  [full_hidden256_vocab16000.txt, full_hidden256...   \n6     trg  [trg_hidden512_vocab16000.txt, trg_hidden512_v...   \n\n                                 transformer_encoder  \\\n0  [zero_hidden512_vocab16000.txt, zero_hidden512...   \n1  [few50_hidden256_vocab16000.txt, few50_hidden2...   \n2  [few100_hidden128_vocab16000.txt, few100_hidde...   \n3  [few150_hidden256_vocab16000.txt, few150_hidde...   \n4  [few200_hidden256_vocab16000.txt, few200_hidde...   \n5  [full_hidden256_vocab16000.txt, full_hidden256...   \n6  [trg_hidden512_vocab16000.txt, trg_hidden512_v...   \n\n                    bert-base-uncased        bert-base-multilingual-cased  \n0     [zero_fc256_lr0.005_frozen.txt]    [zero_fc512_lr0.0005_frozen.txt]  \n1    [few50_fc256_lr0.005_frozen.txt]    [few50_fc256_lr0.005_frozen.txt]  \n2   [few100_fc256_lr0.005_frozen.txt]  [few100_fc512_lr0.0005_frozen.txt]  \n3   [few150_fc512_lr0.005_frozen.txt]   [few150_fc128_lr0.005_frozen.txt]  \n4  [few200_fc512_lr0.0005_frozen.txt]   [few200_fc256_lr0.005_frozen.txt]  \n5    [full_fc512_lr0.0005_frozen.txt]     [full_fc512_lr0.005_frozen.txt]  \n6      [trg_fc512_lr0.005_frozen.txt]      [trg_fc512_lr0.005_frozen.txt]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>[zero_hidden128_vocab16000.txt, zero_hidden128...</td>\n      <td>[zero_hidden512_vocab16000.txt, zero_hidden512...</td>\n      <td>[zero_fc256_lr0.005_frozen.txt]</td>\n      <td>[zero_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>[few50_hidden256_vocab16000.txt, few50_hidden2...</td>\n      <td>[few50_hidden256_vocab16000.txt, few50_hidden2...</td>\n      <td>[few50_fc256_lr0.005_frozen.txt]</td>\n      <td>[few50_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>[few100_hidden256_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_hidden128_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_fc256_lr0.005_frozen.txt]</td>\n      <td>[few100_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_hidden256_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_fc512_lr0.005_frozen.txt]</td>\n      <td>[few150_fc128_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>[few200_hidden512_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_hidden256_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_fc512_lr0.0005_frozen.txt]</td>\n      <td>[few200_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>[full_hidden256_vocab16000.txt, full_hidden256...</td>\n      <td>[full_hidden256_vocab16000.txt, full_hidden256...</td>\n      <td>[full_fc512_lr0.0005_frozen.txt]</td>\n      <td>[full_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>[trg_hidden512_vocab16000.txt, trg_hidden512_v...</td>\n      <td>[trg_hidden512_vocab16000.txt, trg_hidden512_v...</td>\n      <td>[trg_fc512_lr0.005_frozen.txt]</td>\n      <td>[trg_fc512_lr0.005_frozen.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams_dfs_dict['aren']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ar-bg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x2a2ad881d30>",
      "text/html": "<style  type=\"text/css\" >\n#T_7f5f230a_9883_11eb_a76d_a0cec835c16drow0_col3,#T_7f5f230a_9883_11eb_a76d_a0cec835c16drow1_col4,#T_7f5f230a_9883_11eb_a76d_a0cec835c16drow2_col4,#T_7f5f230a_9883_11eb_a76d_a0cec835c16drow3_col4,#T_7f5f230a_9883_11eb_a76d_a0cec835c16drow4_col4,#T_7f5f230a_9883_11eb_a76d_a0cec835c16drow5_col4,#T_7f5f230a_9883_11eb_a76d_a0cec835c16drow6_col4{\n            background:  red;\n        }</style><table id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Setup</th>        <th class=\"col_heading level0 col1\" >logistic_regression</th>        <th class=\"col_heading level0 col2\" >transformer_encoder</th>        <th class=\"col_heading level0 col3\" >bert-base-uncased</th>        <th class=\"col_heading level0 col4\" >bert-base-multilingual-cased</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16dlevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow0_col0\" class=\"data row0 col0\" >zero</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow0_col1\" class=\"data row0 col1\" >0.458805</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow0_col2\" class=\"data row0 col2\" >0.792784</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow0_col3\" class=\"data row0 col3\" >0.807905</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow0_col4\" class=\"data row0 col4\" >0.802720</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16dlevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow1_col0\" class=\"data row1 col0\" >few50</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow1_col1\" class=\"data row1 col1\" >0.794631</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow1_col2\" class=\"data row1 col2\" >0.791141</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow1_col3\" class=\"data row1 col3\" >0.809904</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow1_col4\" class=\"data row1 col4\" >0.814546</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16dlevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow2_col0\" class=\"data row2 col0\" >few100</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow2_col1\" class=\"data row2 col1\" >0.797243</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow2_col2\" class=\"data row2 col2\" >0.814881</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow2_col3\" class=\"data row2 col3\" >0.813654</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow2_col4\" class=\"data row2 col4\" >0.819369</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16dlevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow3_col0\" class=\"data row3 col0\" >few150</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow3_col1\" class=\"data row3 col1\" >0.804574</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow3_col2\" class=\"data row3 col2\" >0.814388</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow3_col3\" class=\"data row3 col3\" >0.817971</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow3_col4\" class=\"data row3 col4\" >0.822597</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16dlevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow4_col0\" class=\"data row4 col0\" >few200</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow4_col1\" class=\"data row4 col1\" >0.802283</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow4_col2\" class=\"data row4 col2\" >0.809488</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow4_col3\" class=\"data row4 col3\" >0.811947</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow4_col4\" class=\"data row4 col4\" >0.820767</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16dlevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow5_col0\" class=\"data row5 col0\" >full</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow5_col1\" class=\"data row5 col1\" >0.813638</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow5_col2\" class=\"data row5 col2\" >0.815279</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow5_col3\" class=\"data row5 col3\" >0.821831</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow5_col4\" class=\"data row5 col4\" >0.826400</td>\n            </tr>\n            <tr>\n                        <th id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16dlevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow6_col0\" class=\"data row6 col0\" >trg</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow6_col1\" class=\"data row6 col1\" >0.813775</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow6_col2\" class=\"data row6 col2\" >0.809617</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow6_col3\" class=\"data row6 col3\" >0.820598</td>\n                        <td id=\"T_7f5f230a_9883_11eb_a76d_a0cec835c16drow6_col4\" class=\"data row6 col4\" >0.825151</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highlight_best_score(best_results_dfs_dict['arbg'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Setup   |   logistic_regression |   transformer_encoder | bert-base-uncased   | bert-base-multilingual-cased   |\n",
      "|---------|-----------------------|-----------------------|---------------------|--------------------------------|\n",
      "| zero    |                0.4588 |                0.7928 | **0.8079**          | 0.8027                         |\n",
      "| few50   |                0.7946 |                0.7911 | 0.8099              | **0.8145**                     |\n",
      "| few100  |                0.7972 |                0.8149 | 0.8137              | **0.8194**                     |\n",
      "| few150  |                0.8046 |                0.8144 | 0.818               | **0.8226**                     |\n",
      "| few200  |                0.8023 |                0.8095 | 0.8119              | **0.8208**                     |\n",
      "| full    |                0.8136 |                0.8153 | 0.8218              | **0.8264**                     |\n",
      "| trg     |                0.8138 |                0.8096 | 0.8206              | **0.8252**                     |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate_markdown(best_results_dfs_dict['arbg']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "    Setup                                logistic_regression  \\\n0    zero  [zero_hidden128_vocab16000.txt, zero_hidden128...   \n1   few50  [few50_hidden256_vocab16000.txt, few50_hidden2...   \n2  few100  [few100_hidden512_vocab16000.txt, few100_hidde...   \n3  few150  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  few200  [few200_hidden512_vocab16000.txt, few200_hidde...   \n5    full  [full_hidden256_vocab16000.txt, full_hidden256...   \n6     trg  [trg_hidden256_vocab16000.txt, trg_hidden256_v...   \n\n                                 transformer_encoder  \\\n0  [zero_hidden512_vocab16000.txt, zero_hidden512...   \n1  [few50_hidden128_vocab16000.txt, few50_hidden1...   \n2  [few100_hidden256_vocab16000.txt, few100_hidde...   \n3  [few150_hidden512_vocab16000.txt, few150_hidde...   \n4  [few200_hidden512_vocab16000.txt, few200_hidde...   \n5  [full_hidden128_vocab16000.txt, full_hidden128...   \n6  [trg_hidden256_vocab16000.txt, trg_hidden256_v...   \n\n                   bert-base-uncased  \\\n0    [zero_fc512_lr0.005_frozen.txt]   \n1   [few50_fc512_lr0.005_frozen.txt]   \n2  [few100_fc128_lr0.005_frozen.txt]   \n3  [few150_fc512_lr0.005_frozen.txt]   \n4  [few200_fc128_lr0.005_frozen.txt]   \n5    [full_fc512_lr0.005_frozen.txt]   \n6     [trg_fc512_lr0.005_frozen.txt]   \n\n                        bert-base-multilingual-cased  \n0  [zero_fc128_lr0.05_trainable.txt, zero_fc256_l...  \n1                  [few50_fc512_lr0.0005_frozen.txt]  \n2                 [few100_fc512_lr0.0005_frozen.txt]  \n3                 [few150_fc128_lr0.0005_frozen.txt]  \n4                 [few200_fc128_lr0.0005_frozen.txt]  \n5                    [full_fc256_lr0.005_frozen.txt]  \n6                     [trg_fc256_lr0.005_frozen.txt]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Setup</th>\n      <th>logistic_regression</th>\n      <th>transformer_encoder</th>\n      <th>bert-base-uncased</th>\n      <th>bert-base-multilingual-cased</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>zero</td>\n      <td>[zero_hidden128_vocab16000.txt, zero_hidden128...</td>\n      <td>[zero_hidden512_vocab16000.txt, zero_hidden512...</td>\n      <td>[zero_fc512_lr0.005_frozen.txt]</td>\n      <td>[zero_fc128_lr0.05_trainable.txt, zero_fc256_l...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>few50</td>\n      <td>[few50_hidden256_vocab16000.txt, few50_hidden2...</td>\n      <td>[few50_hidden128_vocab16000.txt, few50_hidden1...</td>\n      <td>[few50_fc512_lr0.005_frozen.txt]</td>\n      <td>[few50_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>few100</td>\n      <td>[few100_hidden512_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_hidden256_vocab16000.txt, few100_hidde...</td>\n      <td>[few100_fc128_lr0.005_frozen.txt]</td>\n      <td>[few100_fc512_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>few150</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_hidden512_vocab16000.txt, few150_hidde...</td>\n      <td>[few150_fc512_lr0.005_frozen.txt]</td>\n      <td>[few150_fc128_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>few200</td>\n      <td>[few200_hidden512_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_hidden512_vocab16000.txt, few200_hidde...</td>\n      <td>[few200_fc128_lr0.005_frozen.txt]</td>\n      <td>[few200_fc128_lr0.0005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>full</td>\n      <td>[full_hidden256_vocab16000.txt, full_hidden256...</td>\n      <td>[full_hidden128_vocab16000.txt, full_hidden128...</td>\n      <td>[full_fc512_lr0.005_frozen.txt]</td>\n      <td>[full_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>trg</td>\n      <td>[trg_hidden256_vocab16000.txt, trg_hidden256_v...</td>\n      <td>[trg_hidden256_vocab16000.txt, trg_hidden256_v...</td>\n      <td>[trg_fc512_lr0.005_frozen.txt]</td>\n      <td>[trg_fc256_lr0.005_frozen.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hparams_dfs_dict['arbg']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}