03/21/2021 21:39:41 - INFO - __main__ -   

*****************
***RUN STARTED***
*****************

03/21/2021 21:39:41 - INFO - __main__ -   args
-----------------------------------------------------------------------------------------
	srclangs_with_num_samples: ar_all
	trglang: bg
	train_data_dir: ../data/prepared
	dev_data_dir: ../data/prepared
	test_data_dir: None
	batch_size: 4096
	max_vocab_size: 16000
	tokenization: tweet
	hid_dim: 128
	num_enc_layers: 3
	num_enc_heads: 8
	enc_pf_dim: 256
	enc_dropout: 0.1
	fc_dim: 64
	bert_fc_dim: 64
	logistic_regression_hid_dim: 128
	logistic_regression_dropout: 0.1
	log_file_path: ../logs/arbg/transformer_encoder/zero_hidden128_vocab16000.txt
	random_seed: 123
	lr: 0.0005
	clip: 1.0
	max_epochs: 999
	model_dir: ../models/arbg/transformer_encoder/zero_hidden128_vocab16000
	no_xavier_initialization: False
	early_stopping_patience: 10
	model_name: transformer_enc
	freeze_bert: False
-----------------------------------------------------------------------------------------

03/21/2021 21:39:42 - INFO - __main__ -   device: cuda
03/21/2021 21:39:42 - INFO - data_utils.load -   considered 165 (100.00 %) samples out of 165 total samples in ../data/prepared/train.ar.tsv
03/21/2021 21:39:42 - INFO - data_utils.load -   considered 350 (100.00 %) samples out of 350 total samples in ../data/prepared/dev.bg.tsv
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   tokenization: tweet
03/21/2021 21:39:42 - INFO - data_utils.field -   2677 (100.00%) tokens out of 2677 tokens are kept in vocabulary
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   num train samples: 165
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   num val samples: 350
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   num test samples: None
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   train sentence max len: 70
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   val sentence max len: 62
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   train OOV: 0 (0.00%) out of 5965 running tokens are OOV
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   val OOV: 5752 (78.27%) out of 7349 running tokens are OOV
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   look at some train samples ğŸ‘€
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   sample idx: 0, original text: ÙˆØ²Ø§Ø¦Ø±ØªÙŠ ÙƒØ£Ù† Ø¨Ù‡Ø§ Ø­ÙŠØ§Ø¡ ÙÙ„ÙŠØ³ ØªØ²ÙˆØ± Ø¥Ù„Ø§ ÙÙŠ Ø§Ù„Ø¸Ù„Ø§Ù… ÙØ±Ø´Øª Ù„Ù‡Ø§ Ø§Ù„Ù…Ø·Ø§Ø±Ù ÙˆØ§Ù„Ø­Ø´Ø§ÙŠØ§ ÙØ¹Ø§ÙØªÙ‡Ø§ ÙˆØ¨Ø§ØªØª ÙÙŠ Ø¹Ø¸Ø§Ù…ÙŠ ÙŠØ¶ÙŠÙ‚ Ø§Ù„Ø¬Ù„Ø¯ Ø¹Ù† Ù†ÙØ³ÙŠ ÙˆØ¹Ù†Ù‡Ø§ ÙØªÙˆØ³Ø¹Ù‡ Ø¨Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø³Ù‚Ø§Ù… Ø§Ø°Ø§ Ù…Ø§ ÙØ§Ø±Ù‚ØªÙ†ÙŠ ØºØ³Ù„ØªÙ†ÙŠ ÙƒØ£Ù†Ø§ Ø¹Ø§ÙƒÙØ§Ù† Ø¹Ù„Ù‰ Ø­Ø±Ø§Ù… #Ø§Ù„Ù…ØªÙ†Ø¨ÙŠ #Ø§Ù„Ø­Ù…Ù‰ #ÙˆØ¨Ø§Ø¡ #ÙƒÙˆØ±ÙˆÙ†Ø§ #Ø§Ù„ÙƒÙˆÙŠØª #Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© #Ù‚Ø·Ø± #Ø§Ù„Ø§Ù…Ø§Ø±Ø§Øª #Ø§Ù„Ø¨Ø­Ø±ÙŠÙ† #Ø¹Ù…Ø§Ù† URL, preprocessed text: ['<sos>', 'ÙˆØ²Ø§Ø¦Ø±ØªÙŠ', 'ÙƒØ£Ù†', 'Ø¨Ù‡Ø§', 'Ø­ÙŠØ§Ø¡', 'ÙÙ„ÙŠØ³', 'ØªØ²ÙˆØ±', 'Ø¥Ù„Ø§', 'ÙÙŠ', 'Ø§Ù„Ø¸Ù„Ø§Ù…', 'ÙØ±Ø´Øª', 'Ù„Ù‡Ø§', 'Ø§Ù„Ù…Ø·Ø§Ø±Ù', 'ÙˆØ§Ù„Ø­Ø´Ø§ÙŠØ§', 'ÙØ¹Ø§ÙØªÙ‡Ø§', 'ÙˆØ¨Ø§ØªØª', 'ÙÙŠ', 'Ø¹Ø¸Ø§Ù…ÙŠ', 'ÙŠØ¶ÙŠÙ‚', 'Ø§Ù„Ø¬Ù„Ø¯', 'Ø¹Ù†', 'Ù†ÙØ³ÙŠ', 'ÙˆØ¹Ù†Ù‡Ø§', 'ÙØªÙˆØ³Ø¹Ù‡', 'Ø¨Ø£Ù†ÙˆØ§Ø¹', 'Ø§Ù„Ø³Ù‚Ø§Ù…', 'Ø§Ø°Ø§', 'Ù…Ø§', 'ÙØ§Ø±Ù‚ØªÙ†ÙŠ', 'ØºØ³Ù„ØªÙ†ÙŠ', 'ÙƒØ£Ù†Ø§', 'Ø¹Ø§ÙƒÙØ§Ù†', 'Ø¹Ù„Ù‰', 'Ø­Ø±Ø§Ù…', '#Ø§Ù„Ù…ØªÙ†Ø¨ÙŠ', '#Ø§Ù„Ø­Ù…Ù‰', '#ÙˆØ¨Ø§Ø¡', '#ÙƒÙˆØ±ÙˆÙ†Ø§', '#Ø§Ù„ÙƒÙˆÙŠØª', '#Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©', '#Ù‚Ø·Ø±', '#Ø§Ù„Ø§Ù…Ø§Ø±Ø§Øª', '#Ø§Ù„Ø¨Ø­Ø±ÙŠÙ†', '#Ø¹Ù…Ø§Ù†', 'URL'], text ids: [2, 687, 327, 79, 688, 689, 690, 75, 5, 691, 692, 218, 693, 694, 695, 696, 5, 697, 698, 699, 15, 700, 701, 702, 703, 704, 328, 51, 705, 706, 707, 708, 12, 709, 710, 711, 712, 8, 713, 31, 32, 714, 715, 716, 6], original labels: no nan nan nan nan no no, label ids: [[1], [2], [2], [2], [2], [1], [1]]
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   sample idx: 1, original text: Ø¨Ø£Ù…Ø± Ø®Ø§Ø¯Ù… Ø§Ù„Ø­Ø±Ù…ÙŠÙ† Ø§Ù„Ø´Ø±ÙŠÙÙŠÙ†  Ù…Ù†Ø¹ Ø§Ù„ØªØ¬ÙˆÙ„ Ù„Ù„Ø­Ø¯  Ù…Ù† Ø§Ù†ØªØ´Ø§Ø± #ÙÙŠØ±ÙˆØ³_ÙƒÙˆØ±ÙˆÙ†Ø§  Ù…Ù† Ø§Ù„Ø³Ø§Ø¹Ø© 7Ù… Ø­ØªÙ‰ Ø§Ù„Ø³Ø§Ø¹Ø© 6Øµ  Ù„Ù…Ø¯Ø© 21 ÙŠÙˆÙ… URL, preprocessed text: ['<sos>', 'Ø¨Ø£Ù…Ø±', 'Ø®Ø§Ø¯Ù…', 'Ø§Ù„Ø­Ø±Ù…ÙŠÙ†', 'Ø§Ù„Ø´Ø±ÙŠÙÙŠÙ†', 'Ù…Ù†Ø¹', 'Ø§Ù„ØªØ¬ÙˆÙ„', 'Ù„Ù„Ø­Ø¯', 'Ù…Ù†', 'Ø§Ù†ØªØ´Ø§Ø±', '#ÙÙŠØ±ÙˆØ³_ÙƒÙˆØ±ÙˆÙ†Ø§', 'Ù…Ù†', 'Ø§Ù„Ø³Ø§Ø¹Ø©', '7Ù…', 'Ø­ØªÙ‰', 'Ø§Ù„Ø³Ø§Ø¹Ø©', '6Øµ', 'Ù„Ù…Ø¯Ø©', '21', 'ÙŠÙˆÙ…', 'URL'], text ids: [2, 717, 160, 161, 219, 220, 41, 42, 4, 23, 38, 4, 26, 718, 67, 26, 719, 61, 62, 55, 6], original labels: yes no yes no no no no, label ids: [[0], [1], [0], [1], [1], [1], [1]]
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   sample idx: 2, original text: Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª ØªØºØ²Ùˆ Ø§Ù„Ù…Ø¯Ù† Ø¨Ø¹Ø¯ ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø­Ø¸Ø± Ø§Ù„ØªØ¬ÙˆØ§Ù„ Ù„Ù„ÙˆÙ‚Ø§ÙŠØ© Ù…Ù† ÙÙŠØ±ÙˆØ³ ÙƒÙˆØ±ÙˆÙ†Ø§ Ø­ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ØŒ ØµÙˆØ± Ù…Ù† Ø§ÙŠØ·Ø§Ù„ÙŠØ§ Ùˆ Ø§Ù„ÙŠØ§Ø¨Ø§Ù† Ùˆ Ø¬Ø²ÙŠØ±Ø© Ø³Ø±Ø¯ÙŠÙ†ÙŠØ§ .. URL, preprocessed text: ['<sos>', 'Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª', 'ØªØºØ²Ùˆ', 'Ø§Ù„Ù…Ø¯Ù†', 'Ø¨Ø¹Ø¯', 'ØªØ·Ø¨ÙŠÙ‚', 'Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª', 'Ø­Ø¸Ø±', 'Ø§Ù„ØªØ¬ÙˆØ§Ù„', 'Ù„Ù„ÙˆÙ‚Ø§ÙŠØ©', 'Ù…Ù†', 'ÙÙŠØ±ÙˆØ³', 'ÙƒÙˆØ±ÙˆÙ†Ø§', 'Ø­ÙˆÙ„', 'Ø§Ù„Ø¹Ø§Ù„Ù…', 'ØŒ', 'ØµÙˆØ±', 'Ù…Ù†', 'Ø§ÙŠØ·Ø§Ù„ÙŠØ§', 'Ùˆ', 'Ø§Ù„ÙŠØ§Ø¨Ø§Ù†', 'Ùˆ', 'Ø¬Ø²ÙŠØ±Ø©', 'Ø³Ø±Ø¯ÙŠÙ†ÙŠØ§', '..', 'URL'], text ids: [2, 329, 720, 721, 58, 330, 221, 80, 722, 222, 4, 18, 10, 162, 35, 7, 723, 4, 331, 36, 724, 36, 725, 726, 9, 6], original labels: yes yes nan yes yes yes yes, label ids: [[0], [0], [2], [0], [0], [0], [0]]
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   sample idx: 3, original text: ØªÙˆØ§Ø¬Ù‡ Ù‚Ù†Ø§ØªÙŠ: (ÙŠÙˆØ³Ù Ø¹Ù„Ø§ÙˆÙ†Ø© Ù…Ø¨Ø§Ø´Ø±) Ø­Ù…Ù„Ø© Ø´Ø¹ÙˆØ§Ø¡ Ù…Ù† Ø¨Ù‡Ø§ÙŠÙ… Ø­Ù„Ù Ø§Ù„Ù„Ø·Ù… ÙˆØªØ¶Ù…Ù† Ù‡Ø°Ø§ Ø¯ÙØ¹ Ø±Ø´Ø§ÙˆÙ‰ Ù„ØªØ¹Ø·ÙŠÙ„ Ø§Ù„Ø§Ø´ØªØ±Ø§ÙƒØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©  Ø¨Ø±Ø¬Ø§Ø¡ ØªØ¬Ø¯ÙŠØ¯ Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ ÙˆØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¬Ø±Ø³  ÙˆÙ†Ø´Ø± Ù‡Ø°Ù‡ Ø§Ù„ØªØºØ±ÙŠØ¯Ø© #ÙƒÙˆØ±ÙˆÙ†Ø§ #Ø§ÙˆØ§Ù…Ø±_Ù…Ù„ÙƒÙŠØ© #Covid_19 #Ù‚Ø·Ø± #ØªØ±Ùƒ #Ù…Ø¬ÙˆØ³ #Ø§Ø®ÙˆØ§Ù† #Ø§Ø­Ø°ÙŠØ© #Ø±ÙˆØ§ÙØ¶ #Ø®ÙˆØ§Ø±Ø¬ #ÙŠÙˆØ³Ù_Ø¹Ù„Ø§ÙˆÙ†Ø©  URL, preprocessed text: ['<sos>', 'ØªÙˆØ§Ø¬Ù‡', 'Ù‚Ù†Ø§ØªÙŠ', ':', '(', 'ÙŠÙˆØ³Ù', 'Ø¹Ù„Ø§ÙˆÙ†Ø©', 'Ù…Ø¨Ø§Ø´Ø±', ')', 'Ø­Ù…Ù„Ø©', 'Ø´Ø¹ÙˆØ§Ø¡', 'Ù…Ù†', 'Ø¨Ù‡Ø§ÙŠÙ…', 'Ø­Ù„Ù', 'Ø§Ù„Ù„Ø·Ù…', 'ÙˆØªØ¶Ù…Ù†', 'Ù‡Ø°Ø§', 'Ø¯ÙØ¹', 'Ø±Ø´Ø§ÙˆÙ‰', 'Ù„ØªØ¹Ø·ÙŠÙ„', 'Ø§Ù„Ø§Ø´ØªØ±Ø§ÙƒØ§Øª', 'Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©', 'Ø¨Ø±Ø¬Ø§Ø¡', 'ØªØ¬Ø¯ÙŠØ¯', 'Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ', 'ÙˆØªÙØ¹ÙŠÙ„', 'Ø§Ù„Ø¬Ø±Ø³', 'ÙˆÙ†Ø´Ø±', 'Ù‡Ø°Ù‡', 'Ø§Ù„ØªØºØ±ÙŠØ¯Ø©', '#ÙƒÙˆØ±ÙˆÙ†Ø§', '#Ø§ÙˆØ§Ù…Ø±_Ù…Ù„ÙƒÙŠØ©', '#Covid_19', '#Ù‚Ø·Ø±', '#ØªØ±Ùƒ', '#Ù…Ø¬ÙˆØ³', '#Ø§Ø®ÙˆØ§Ù†', '#Ø§Ø­Ø°ÙŠØ©', '#Ø±ÙˆØ§ÙØ¶', '#Ø®ÙˆØ§Ø±Ø¬', '#ÙŠÙˆØ³Ù_Ø¹Ù„Ø§ÙˆÙ†Ø©', 'URL'], text ids: [2, 332, 727, 11, 13, 728, 729, 730, 14, 731, 732, 4, 733, 734, 735, 736, 56, 737, 738, 739, 740, 333, 741, 742, 743, 744, 745, 334, 52, 223, 8, 746, 224, 32, 747, 748, 749, 750, 751, 752, 753, 6], original labels: no nan nan nan nan no no, label ids: [[1], [2], [2], [2], [2], [1], [1]]
03/21/2021 21:39:42 - INFO - data_utils.preprocess -   sample idx: 4, original text: Ø¥ØµØ§Ø¨Ø© Ø¹Ø§Ù…Ù„ÙŠÙ† Ø¨Ù…Ø´Ø±ÙˆØ¹Ø§Øª ÙƒØ£Ø³ Ø§Ù„Ø¹Ø§Ù„Ù… ÙÙŠ Ù‚Ø·Ø± Ø¨Ù€ #ÙƒÙˆØ±ÙˆÙ†Ø§ #Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©_Ø¹Ø§Ø¬Ù„ URL, preprocessed text: ['<sos>', 'Ø¥ØµØ§Ø¨Ø©', 'Ø¹Ø§Ù…Ù„ÙŠÙ†', 'Ø¨Ù…Ø´Ø±ÙˆØ¹Ø§Øª', 'ÙƒØ£Ø³', 'Ø§Ù„Ø¹Ø§Ù„Ù…', 'ÙÙŠ', 'Ù‚Ø·Ø±', 'Ø¨Ù€', '#ÙƒÙˆØ±ÙˆÙ†Ø§', '#Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©_Ø¹Ø§Ø¬Ù„', 'URL'], text ids: [2, 28, 754, 755, 756, 35, 5, 29, 163, 8, 335, 6], original labels: yes yes yes yes yes yes yes, label ids: [[0], [0], [0], [0], [0], [0], [0]]
03/21/2021 21:39:44 - INFO - data_utils.preprocess -   there are nearly 3 batches in an epoch
03/21/2021 21:39:44 - INFO - __main__ -   model
-----------------------------------------------------------------------------------------
MultitaskTransformerEncoderClassificationModel(
  (encoder): Encoder(
    (tok_embedding): Embedding(2680, 128)
    (pos_embedding): Embedding(1000, 128)
    (layers): ModuleList(
      (0): EncoderLayer(
        (layer_norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)
        (self_attention): SelfAttentionLayer(
          (fc_q): Linear(in_features=128, out_features=128, bias=True)
          (fc_k): Linear(in_features=128, out_features=128, bias=True)
          (fc_v): Linear(in_features=128, out_features=128, bias=True)
          (fc): Linear(in_features=128, out_features=128, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (positionwise_feedforward): PositionwiseFeedforwardLayer(
          (fc_1): Linear(in_features=128, out_features=256, bias=True)
          (fc_2): Linear(in_features=256, out_features=128, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (dropout): Dropout(p=0.1)
      )
      (1): EncoderLayer(
        (layer_norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)
        (self_attention): SelfAttentionLayer(
          (fc_q): Linear(in_features=128, out_features=128, bias=True)
          (fc_k): Linear(in_features=128, out_features=128, bias=True)
          (fc_v): Linear(in_features=128, out_features=128, bias=True)
          (fc): Linear(in_features=128, out_features=128, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (positionwise_feedforward): PositionwiseFeedforwardLayer(
          (fc_1): Linear(in_features=128, out_features=256, bias=True)
          (fc_2): Linear(in_features=256, out_features=128, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (dropout): Dropout(p=0.1)
      )
      (2): EncoderLayer(
        (layer_norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)
        (self_attention): SelfAttentionLayer(
          (fc_q): Linear(in_features=128, out_features=128, bias=True)
          (fc_k): Linear(in_features=128, out_features=128, bias=True)
          (fc_v): Linear(in_features=128, out_features=128, bias=True)
          (fc): Linear(in_features=128, out_features=128, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (positionwise_feedforward): PositionwiseFeedforwardLayer(
          (fc_1): Linear(in_features=128, out_features=256, bias=True)
          (fc_2): Linear(in_features=256, out_features=128, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (dropout): Dropout(p=0.1)
      )
    )
    (dropout): Dropout(p=0.1)
  )
  (fc): Linear(in_features=128, out_features=64, bias=True)
  (clfs): ModuleList(
    (0): Linear(in_features=64, out_features=3, bias=True)
    (1): Linear(in_features=64, out_features=3, bias=True)
    (2): Linear(in_features=64, out_features=3, bias=True)
    (3): Linear(in_features=64, out_features=3, bias=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Linear(in_features=64, out_features=3, bias=True)
    (6): Linear(in_features=64, out_features=3, bias=True)
  )
)
-----------------------------------------------------------------------------------------

03/21/2021 21:39:44 - INFO - __main__ -   the model has 877,333 trainable parameters
03/21/2021 21:39:44 - INFO - __main__ -   applying xavier initialization of model parameters
03/21/2021 21:39:44 - INFO - __main__ -   ğŸŒ‹  starting training..
03/21/2021 21:39:44 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:39:44 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:44 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:39:44 - INFO - training_utils.postprocess -   526 (37.57 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:44 - INFO - __main__ -   Epoch: 0001 | Time: 0m_0s | train_loss: 9.527 | val_loss: 7.193
03/21/2021 21:39:44 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.3142857142857142, 'f1': 0.2630126230400727, 'precision': 0.2630126230400727, 'recall': 0.2630126230400727}
03/21/2021 21:39:44 - INFO - __main__ -   	--Found new best val f1
03/21/2021 21:39:44 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:39:44 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:44 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:39:44 - INFO - training_utils.postprocess -   358 (25.57 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:45 - INFO - __main__ -   Epoch: 0002 | Time: 0m_0s | train_loss: 6.421 | val_loss: 6.680
03/21/2021 21:39:45 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.2861224489795918, 'f1': 0.2034763752869746, 'precision': 0.2034763752869746, 'recall': 0.2034763752869746}
03/21/2021 21:39:45 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:39:45 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:45 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:39:45 - INFO - training_utils.postprocess -   349 (24.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:45 - INFO - __main__ -   Epoch: 0003 | Time: 0m_0s | train_loss: 5.841 | val_loss: 6.523
03/21/2021 21:39:45 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.30326530612244895, 'f1': 0.21094792875512977, 'precision': 0.21094792875512977, 'recall': 0.21094792875512977}
03/21/2021 21:39:45 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:39:45 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:45 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:39:45 - INFO - training_utils.postprocess -   250 (17.86 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:45 - INFO - __main__ -   Epoch: 0004 | Time: 0m_0s | train_loss: 5.308 | val_loss: 6.297
03/21/2021 21:39:45 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.3669387755102041, 'f1': 0.32547550514646645, 'precision': 0.32547550514646645, 'recall': 0.32547550514646645}
03/21/2021 21:39:45 - INFO - __main__ -   	--Found new best val f1
03/21/2021 21:39:45 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:39:45 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:45 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:39:45 - INFO - training_utils.postprocess -   106 (7.57 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:45 - INFO - __main__ -   Epoch: 0005 | Time: 0m_0s | train_loss: 4.451 | val_loss: 6.949
03/21/2021 21:39:45 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.31061224489795913, 'f1': 0.22728849898896272, 'precision': 0.22728849898896272, 'recall': 0.22728849898896272}
03/21/2021 21:39:45 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:39:45 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:45 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:39:45 - INFO - training_utils.postprocess -   58 (4.14 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:45 - INFO - __main__ -   Epoch: 0006 | Time: 0m_0s | train_loss: 3.506 | val_loss: 7.967
03/21/2021 21:39:45 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.3110204081632653, 'f1': 0.23008344673312653, 'precision': 0.23008344673312653, 'recall': 0.23008344673312653}
03/21/2021 21:39:45 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:39:45 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:45 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:39:45 - INFO - training_utils.postprocess -   39 (2.79 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:45 - INFO - __main__ -   Epoch: 0007 | Time: 0m_0s | train_loss: 2.356 | val_loss: 9.829
03/21/2021 21:39:45 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.3208163265306122, 'f1': 0.25432316518626585, 'precision': 0.25432316518626585, 'recall': 0.25432316518626585}
03/21/2021 21:39:46 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:39:46 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:46 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:39:46 - INFO - training_utils.postprocess -   34 (2.43 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:46 - INFO - __main__ -   Epoch: 0008 | Time: 0m_0s | train_loss: 1.890 | val_loss: 11.335
03/21/2021 21:39:46 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.3355102040816327, 'f1': 0.3007000935130271, 'precision': 0.3007000935130271, 'recall': 0.3007000935130271}
03/21/2021 21:39:46 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:39:46 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:46 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:39:46 - INFO - training_utils.postprocess -   82 (5.86 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:46 - INFO - __main__ -   Epoch: 0009 | Time: 0m_0s | train_loss: 1.567 | val_loss: 10.757
03/21/2021 21:39:46 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.34653061224489795, 'f1': 0.37108034383101074, 'precision': 0.37108034383101074, 'recall': 0.37108034383101074}
03/21/2021 21:39:46 - INFO - __main__ -   	--Found new best val f1
03/21/2021 21:39:46 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:39:46 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:46 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:39:46 - INFO - training_utils.postprocess -   96 (6.86 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:46 - INFO - __main__ -   Epoch: 0010 | Time: 0m_0s | train_loss: 1.083 | val_loss: 12.012
03/21/2021 21:39:46 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.32816326530612244, 'f1': 0.3495653142031885, 'precision': 0.3495653142031885, 'recall': 0.3495653142031885}
03/21/2021 21:39:46 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:39:46 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:46 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:39:46 - INFO - training_utils.postprocess -   90 (6.43 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:46 - INFO - __main__ -   Epoch: 0011 | Time: 0m_0s | train_loss: 1.139 | val_loss: 9.154
03/21/2021 21:39:46 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.3971428571428572, 'f1': 0.47211645716978784, 'precision': 0.47211645716978784, 'recall': 0.47211645716978784}
03/21/2021 21:39:46 - INFO - __main__ -   	--Found new best val f1
03/21/2021 21:39:46 - INFO - __main__ -   	--STOPPING EARLY
03/21/2021 21:39:46 - INFO - __main__ -   load checkpoint from ../models/arbg/transformer_encoder/zero_hidden128_vocab16000
03/21/2021 21:39:46 - INFO - __main__ -   load model weights from checkpoint in ../models/arbg/transformer_encoder/zero_hidden128_vocab16000
03/21/2021 21:39:46 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:39:46 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:46 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:39:46 - INFO - training_utils.postprocess -   90 (6.43 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:39:46 - INFO - __main__ -   best_val_loss: 9.154
03/21/2021 21:39:46 - INFO - __main__ -   ğŸ“£ best validation metrics ğŸ“£ {'acc': 0.3971428571428572, 'f1': 0.47211645716978784, 'precision': 0.47211645716978784, 'recall': 0.47211645716978784}
