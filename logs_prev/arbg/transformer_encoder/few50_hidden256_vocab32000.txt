03/21/2021 21:42:14 - INFO - __main__ -   

*****************
***RUN STARTED***
*****************

03/21/2021 21:42:14 - INFO - __main__ -   args
-----------------------------------------------------------------------------------------
	srclangs_with_num_samples: ar_all,bg_50
	trglang: bg
	train_data_dir: ../data/prepared
	dev_data_dir: ../data/prepared
	test_data_dir: None
	batch_size: 4096
	max_vocab_size: 32000
	tokenization: tweet
	hid_dim: 256
	num_enc_layers: 3
	num_enc_heads: 8
	enc_pf_dim: 256
	enc_dropout: 0.1
	fc_dim: 64
	bert_fc_dim: 64
	logistic_regression_hid_dim: 128
	logistic_regression_dropout: 0.1
	log_file_path: ../logs/arbg/transformer_encoder/few50_hidden256_vocab32000.txt
	random_seed: 123
	lr: 0.0005
	clip: 1.0
	max_epochs: 999
	model_dir: ../models/arbg/transformer_encoder/few50_hidden256_vocab32000
	no_xavier_initialization: False
	early_stopping_patience: 10
	model_name: transformer_enc
	freeze_bert: False
-----------------------------------------------------------------------------------------

03/21/2021 21:42:15 - INFO - __main__ -   device: cuda
03/21/2021 21:42:15 - INFO - data_utils.load -   considered 165 (100.00 %) samples out of 165 total samples in ../data/prepared/train.ar.tsv
03/21/2021 21:42:15 - INFO - data_utils.load -   considered 50 (1.67 %) samples out of 3000 total samples in ../data/prepared/train.bg.tsv
03/21/2021 21:42:15 - INFO - data_utils.load -   considered 350 (100.00 %) samples out of 350 total samples in ../data/prepared/dev.bg.tsv
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   tokenization: tweet
03/21/2021 21:42:15 - INFO - data_utils.field -   3359 (100.00%) tokens out of 3359 tokens are kept in vocabulary
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   num train samples: 215
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   num val samples: 350
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   num test samples: None
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   train sentence max len: 344
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   val sentence max len: 62
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   train OOV: 0 (0.00%) out of 7517 running tokens are OOV
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   val OOV: 2732 (37.18%) out of 7349 running tokens are OOV
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   look at some train samples ğŸ‘€
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   sample idx: 0, original text: ÙˆØ²Ø§Ø¦Ø±ØªÙŠ ÙƒØ£Ù† Ø¨Ù‡Ø§ Ø­ÙŠØ§Ø¡ ÙÙ„ÙŠØ³ ØªØ²ÙˆØ± Ø¥Ù„Ø§ ÙÙŠ Ø§Ù„Ø¸Ù„Ø§Ù… ÙØ±Ø´Øª Ù„Ù‡Ø§ Ø§Ù„Ù…Ø·Ø§Ø±Ù ÙˆØ§Ù„Ø­Ø´Ø§ÙŠØ§ ÙØ¹Ø§ÙØªÙ‡Ø§ ÙˆØ¨Ø§ØªØª ÙÙŠ Ø¹Ø¸Ø§Ù…ÙŠ ÙŠØ¶ÙŠÙ‚ Ø§Ù„Ø¬Ù„Ø¯ Ø¹Ù† Ù†ÙØ³ÙŠ ÙˆØ¹Ù†Ù‡Ø§ ÙØªÙˆØ³Ø¹Ù‡ Ø¨Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø³Ù‚Ø§Ù… Ø§Ø°Ø§ Ù…Ø§ ÙØ§Ø±Ù‚ØªÙ†ÙŠ ØºØ³Ù„ØªÙ†ÙŠ ÙƒØ£Ù†Ø§ Ø¹Ø§ÙƒÙØ§Ù† Ø¹Ù„Ù‰ Ø­Ø±Ø§Ù… #Ø§Ù„Ù…ØªÙ†Ø¨ÙŠ #Ø§Ù„Ø­Ù…Ù‰ #ÙˆØ¨Ø§Ø¡ #ÙƒÙˆØ±ÙˆÙ†Ø§ #Ø§Ù„ÙƒÙˆÙŠØª #Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© #Ù‚Ø·Ø± #Ø§Ù„Ø§Ù…Ø§Ø±Ø§Øª #Ø§Ù„Ø¨Ø­Ø±ÙŠÙ† #Ø¹Ù…Ø§Ù† URL, preprocessed text: ['<sos>', 'ÙˆØ²Ø§Ø¦Ø±ØªÙŠ', 'ÙƒØ£Ù†', 'Ø¨Ù‡Ø§', 'Ø­ÙŠØ§Ø¡', 'ÙÙ„ÙŠØ³', 'ØªØ²ÙˆØ±', 'Ø¥Ù„Ø§', 'ÙÙŠ', 'Ø§Ù„Ø¸Ù„Ø§Ù…', 'ÙØ±Ø´Øª', 'Ù„Ù‡Ø§', 'Ø§Ù„Ù…Ø·Ø§Ø±Ù', 'ÙˆØ§Ù„Ø­Ø´Ø§ÙŠØ§', 'ÙØ¹Ø§ÙØªÙ‡Ø§', 'ÙˆØ¨Ø§ØªØª', 'ÙÙŠ', 'Ø¹Ø¸Ø§Ù…ÙŠ', 'ÙŠØ¶ÙŠÙ‚', 'Ø§Ù„Ø¬Ù„Ø¯', 'Ø¹Ù†', 'Ù†ÙØ³ÙŠ', 'ÙˆØ¹Ù†Ù‡Ø§', 'ÙØªÙˆØ³Ø¹Ù‡', 'Ø¨Ø£Ù†ÙˆØ§Ø¹', 'Ø§Ù„Ø³Ù‚Ø§Ù…', 'Ø§Ø°Ø§', 'Ù…Ø§', 'ÙØ§Ø±Ù‚ØªÙ†ÙŠ', 'ØºØ³Ù„ØªÙ†ÙŠ', 'ÙƒØ£Ù†Ø§', 'Ø¹Ø§ÙƒÙØ§Ù†', 'Ø¹Ù„Ù‰', 'Ø­Ø±Ø§Ù…', '#Ø§Ù„Ù…ØªÙ†Ø¨ÙŠ', '#Ø§Ù„Ø­Ù…Ù‰', '#ÙˆØ¨Ø§Ø¡', '#ÙƒÙˆØ±ÙˆÙ†Ø§', '#Ø§Ù„ÙƒÙˆÙŠØª', '#Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©', '#Ù‚Ø·Ø±', '#Ø§Ù„Ø§Ù…Ø§Ø±Ø§Øª', '#Ø§Ù„Ø¨Ø­Ø±ÙŠÙ†', '#Ø¹Ù…Ø§Ù†', 'URL'], text ids: [2, 853, 389, 102, 854, 855, 856, 98, 5, 857, 858, 263, 859, 860, 861, 862, 5, 863, 864, 865, 20, 866, 867, 868, 869, 870, 390, 65, 871, 872, 873, 874, 15, 875, 876, 877, 878, 8, 879, 41, 45, 880, 881, 882, 6], original labels: no nan nan nan nan no no, label ids: [[1], [2], [2], [2], [2], [1], [1]]
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   sample idx: 1, original text: Ø¨Ø£Ù…Ø± Ø®Ø§Ø¯Ù… Ø§Ù„Ø­Ø±Ù…ÙŠÙ† Ø§Ù„Ø´Ø±ÙŠÙÙŠÙ†  Ù…Ù†Ø¹ Ø§Ù„ØªØ¬ÙˆÙ„ Ù„Ù„Ø­Ø¯  Ù…Ù† Ø§Ù†ØªØ´Ø§Ø± #ÙÙŠØ±ÙˆØ³_ÙƒÙˆØ±ÙˆÙ†Ø§  Ù…Ù† Ø§Ù„Ø³Ø§Ø¹Ø© 7Ù… Ø­ØªÙ‰ Ø§Ù„Ø³Ø§Ø¹Ø© 6Øµ  Ù„Ù…Ø¯Ø© 21 ÙŠÙˆÙ… URL, preprocessed text: ['<sos>', 'Ø¨Ø£Ù…Ø±', 'Ø®Ø§Ø¯Ù…', 'Ø§Ù„Ø­Ø±Ù…ÙŠÙ†', 'Ø§Ù„Ø´Ø±ÙŠÙÙŠÙ†', 'Ù…Ù†Ø¹', 'Ø§Ù„ØªØ¬ÙˆÙ„', 'Ù„Ù„Ø­Ø¯', 'Ù…Ù†', 'Ø§Ù†ØªØ´Ø§Ø±', '#ÙÙŠØ±ÙˆØ³_ÙƒÙˆØ±ÙˆÙ†Ø§', 'Ù…Ù†', 'Ø§Ù„Ø³Ø§Ø¹Ø©', '7Ù…', 'Ø­ØªÙ‰', 'Ø§Ù„Ø³Ø§Ø¹Ø©', '6Øµ', 'Ù„Ù…Ø¯Ø©', '21', 'ÙŠÙˆÙ…', 'URL'], text ids: [2, 883, 191, 192, 264, 265, 55, 56, 4, 35, 52, 4, 37, 884, 84, 37, 885, 77, 78, 69, 6], original labels: yes no yes no no no no, label ids: [[0], [1], [0], [1], [1], [1], [1]]
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   sample idx: 2, original text: Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª ØªØºØ²Ùˆ Ø§Ù„Ù…Ø¯Ù† Ø¨Ø¹Ø¯ ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø­Ø¸Ø± Ø§Ù„ØªØ¬ÙˆØ§Ù„ Ù„Ù„ÙˆÙ‚Ø§ÙŠØ© Ù…Ù† ÙÙŠØ±ÙˆØ³ ÙƒÙˆØ±ÙˆÙ†Ø§ Ø­ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ØŒ ØµÙˆØ± Ù…Ù† Ø§ÙŠØ·Ø§Ù„ÙŠØ§ Ùˆ Ø§Ù„ÙŠØ§Ø¨Ø§Ù† Ùˆ Ø¬Ø²ÙŠØ±Ø© Ø³Ø±Ø¯ÙŠÙ†ÙŠØ§ .. URL, preprocessed text: ['<sos>', 'Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª', 'ØªØºØ²Ùˆ', 'Ø§Ù„Ù…Ø¯Ù†', 'Ø¨Ø¹Ø¯', 'ØªØ·Ø¨ÙŠÙ‚', 'Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª', 'Ø­Ø¸Ø±', 'Ø§Ù„ØªØ¬ÙˆØ§Ù„', 'Ù„Ù„ÙˆÙ‚Ø§ÙŠØ©', 'Ù…Ù†', 'ÙÙŠØ±ÙˆØ³', 'ÙƒÙˆØ±ÙˆÙ†Ø§', 'Ø­ÙˆÙ„', 'Ø§Ù„Ø¹Ø§Ù„Ù…', 'ØŒ', 'ØµÙˆØ±', 'Ù…Ù†', 'Ø§ÙŠØ·Ø§Ù„ÙŠØ§', 'Ùˆ', 'Ø§Ù„ÙŠØ§Ø¨Ø§Ù†', 'Ùˆ', 'Ø¬Ø²ÙŠØ±Ø©', 'Ø³Ø±Ø¯ÙŠÙ†ÙŠØ§', '..', 'URL'], text ids: [2, 391, 886, 887, 73, 392, 266, 103, 888, 267, 4, 28, 10, 193, 49, 7, 889, 4, 393, 50, 890, 50, 891, 892, 9, 6], original labels: yes yes nan yes yes yes yes, label ids: [[0], [0], [2], [0], [0], [0], [0]]
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   sample idx: 3, original text: ØªÙˆØ§Ø¬Ù‡ Ù‚Ù†Ø§ØªÙŠ: (ÙŠÙˆØ³Ù Ø¹Ù„Ø§ÙˆÙ†Ø© Ù…Ø¨Ø§Ø´Ø±) Ø­Ù…Ù„Ø© Ø´Ø¹ÙˆØ§Ø¡ Ù…Ù† Ø¨Ù‡Ø§ÙŠÙ… Ø­Ù„Ù Ø§Ù„Ù„Ø·Ù… ÙˆØªØ¶Ù…Ù† Ù‡Ø°Ø§ Ø¯ÙØ¹ Ø±Ø´Ø§ÙˆÙ‰ Ù„ØªØ¹Ø·ÙŠÙ„ Ø§Ù„Ø§Ø´ØªØ±Ø§ÙƒØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©  Ø¨Ø±Ø¬Ø§Ø¡ ØªØ¬Ø¯ÙŠØ¯ Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ ÙˆØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¬Ø±Ø³  ÙˆÙ†Ø´Ø± Ù‡Ø°Ù‡ Ø§Ù„ØªØºØ±ÙŠØ¯Ø© #ÙƒÙˆØ±ÙˆÙ†Ø§ #Ø§ÙˆØ§Ù…Ø±_Ù…Ù„ÙƒÙŠØ© #Covid_19 #Ù‚Ø·Ø± #ØªØ±Ùƒ #Ù…Ø¬ÙˆØ³ #Ø§Ø®ÙˆØ§Ù† #Ø§Ø­Ø°ÙŠØ© #Ø±ÙˆØ§ÙØ¶ #Ø®ÙˆØ§Ø±Ø¬ #ÙŠÙˆØ³Ù_Ø¹Ù„Ø§ÙˆÙ†Ø©  URL, preprocessed text: ['<sos>', 'ØªÙˆØ§Ø¬Ù‡', 'Ù‚Ù†Ø§ØªÙŠ', ':', '(', 'ÙŠÙˆØ³Ù', 'Ø¹Ù„Ø§ÙˆÙ†Ø©', 'Ù…Ø¨Ø§Ø´Ø±', ')', 'Ø­Ù…Ù„Ø©', 'Ø´Ø¹ÙˆØ§Ø¡', 'Ù…Ù†', 'Ø¨Ù‡Ø§ÙŠÙ…', 'Ø­Ù„Ù', 'Ø§Ù„Ù„Ø·Ù…', 'ÙˆØªØ¶Ù…Ù†', 'Ù‡Ø°Ø§', 'Ø¯ÙØ¹', 'Ø±Ø´Ø§ÙˆÙ‰', 'Ù„ØªØ¹Ø·ÙŠÙ„', 'Ø§Ù„Ø§Ø´ØªØ±Ø§ÙƒØ§Øª', 'Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©', 'Ø¨Ø±Ø¬Ø§Ø¡', 'ØªØ¬Ø¯ÙŠØ¯', 'Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ', 'ÙˆØªÙØ¹ÙŠÙ„', 'Ø§Ù„Ø¬Ø±Ø³', 'ÙˆÙ†Ø´Ø±', 'Ù‡Ø°Ù‡', 'Ø§Ù„ØªØºØ±ÙŠØ¯Ø©', '#ÙƒÙˆØ±ÙˆÙ†Ø§', '#Ø§ÙˆØ§Ù…Ø±_Ù…Ù„ÙƒÙŠØ©', '#Covid_19', '#Ù‚Ø·Ø±', '#ØªØ±Ùƒ', '#Ù…Ø¬ÙˆØ³', '#Ø§Ø®ÙˆØ§Ù†', '#Ø§Ø­Ø°ÙŠØ©', '#Ø±ÙˆØ§ÙØ¶', '#Ø®ÙˆØ§Ø±Ø¬', '#ÙŠÙˆØ³Ù_Ø¹Ù„Ø§ÙˆÙ†Ø©', 'URL'], text ids: [2, 394, 893, 11, 17, 894, 895, 896, 16, 897, 898, 4, 899, 900, 901, 902, 70, 903, 904, 905, 906, 395, 907, 908, 909, 910, 911, 396, 66, 268, 8, 912, 194, 45, 913, 914, 915, 916, 917, 918, 919, 6], original labels: no nan nan nan nan no no, label ids: [[1], [2], [2], [2], [2], [1], [1]]
03/21/2021 21:42:15 - INFO - data_utils.preprocess -   sample idx: 4, original text: Ø¥ØµØ§Ø¨Ø© Ø¹Ø§Ù…Ù„ÙŠÙ† Ø¨Ù…Ø´Ø±ÙˆØ¹Ø§Øª ÙƒØ£Ø³ Ø§Ù„Ø¹Ø§Ù„Ù… ÙÙŠ Ù‚Ø·Ø± Ø¨Ù€ #ÙƒÙˆØ±ÙˆÙ†Ø§ #Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©_Ø¹Ø§Ø¬Ù„ URL, preprocessed text: ['<sos>', 'Ø¥ØµØ§Ø¨Ø©', 'Ø¹Ø§Ù…Ù„ÙŠÙ†', 'Ø¨Ù…Ø´Ø±ÙˆØ¹Ø§Øª', 'ÙƒØ£Ø³', 'Ø§Ù„Ø¹Ø§Ù„Ù…', 'ÙÙŠ', 'Ù‚Ø·Ø±', 'Ø¨Ù€', '#ÙƒÙˆØ±ÙˆÙ†Ø§', '#Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©_Ø¹Ø§Ø¬Ù„', 'URL'], text ids: [2, 39, 920, 921, 922, 49, 5, 40, 195, 8, 397, 6], original labels: yes yes yes yes yes yes yes, label ids: [[0], [0], [0], [0], [0], [0], [0]]
03/21/2021 21:42:17 - INFO - data_utils.preprocess -   there are nearly 4 batches in an epoch
03/21/2021 21:42:17 - INFO - __main__ -   model
-----------------------------------------------------------------------------------------
MultitaskTransformerEncoderClassificationModel(
  (encoder): Encoder(
    (tok_embedding): Embedding(3362, 256)
    (pos_embedding): Embedding(1000, 256)
    (layers): ModuleList(
      (0): EncoderLayer(
        (layer_norm): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (self_attention): SelfAttentionLayer(
          (fc_q): Linear(in_features=256, out_features=256, bias=True)
          (fc_k): Linear(in_features=256, out_features=256, bias=True)
          (fc_v): Linear(in_features=256, out_features=256, bias=True)
          (fc): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (positionwise_feedforward): PositionwiseFeedforwardLayer(
          (fc_1): Linear(in_features=256, out_features=256, bias=True)
          (fc_2): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (dropout): Dropout(p=0.1)
      )
      (1): EncoderLayer(
        (layer_norm): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (self_attention): SelfAttentionLayer(
          (fc_q): Linear(in_features=256, out_features=256, bias=True)
          (fc_k): Linear(in_features=256, out_features=256, bias=True)
          (fc_v): Linear(in_features=256, out_features=256, bias=True)
          (fc): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (positionwise_feedforward): PositionwiseFeedforwardLayer(
          (fc_1): Linear(in_features=256, out_features=256, bias=True)
          (fc_2): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (dropout): Dropout(p=0.1)
      )
      (2): EncoderLayer(
        (layer_norm): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (self_attention): SelfAttentionLayer(
          (fc_q): Linear(in_features=256, out_features=256, bias=True)
          (fc_k): Linear(in_features=256, out_features=256, bias=True)
          (fc_v): Linear(in_features=256, out_features=256, bias=True)
          (fc): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (positionwise_feedforward): PositionwiseFeedforwardLayer(
          (fc_1): Linear(in_features=256, out_features=256, bias=True)
          (fc_2): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1)
        )
        (dropout): Dropout(p=0.1)
      )
    )
    (dropout): Dropout(p=0.1)
  )
  (fc): Linear(in_features=256, out_features=64, bias=True)
  (clfs): ModuleList(
    (0): Linear(in_features=64, out_features=3, bias=True)
    (1): Linear(in_features=64, out_features=3, bias=True)
    (2): Linear(in_features=64, out_features=3, bias=True)
    (3): Linear(in_features=64, out_features=3, bias=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Linear(in_features=64, out_features=3, bias=True)
    (6): Linear(in_features=64, out_features=3, bias=True)
  )
)
-----------------------------------------------------------------------------------------

03/21/2021 21:42:17 - INFO - __main__ -   the model has 2,320,277 trainable parameters
03/21/2021 21:42:17 - INFO - __main__ -   applying xavier initialization of model parameters
03/21/2021 21:42:17 - INFO - __main__ -   ğŸŒ‹  starting training..
03/21/2021 21:42:17 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:42:17 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:17 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:42:17 - INFO - training_utils.postprocess -   0 (0.00 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:17 - INFO - __main__ -   Epoch: 0001 | Time: 0m_0s | train_loss: 7.807 | val_loss: 5.444
03/21/2021 21:42:17 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.6510204081632655, 'f1': 0.6559457243992292, 'precision': 0.6559457243992292, 'recall': 0.6559457243992292}
03/21/2021 21:42:17 - INFO - __main__ -   	--Found new best val f1
03/21/2021 21:42:17 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:42:17 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:17 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:42:17 - INFO - training_utils.postprocess -   91 (6.50 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:17 - INFO - __main__ -   Epoch: 0002 | Time: 0m_0s | train_loss: 5.336 | val_loss: 7.310
03/21/2021 21:42:17 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.3024489795918367, 'f1': 0.20922330848210105, 'precision': 0.20922330848210105, 'recall': 0.20922330848210105}
03/21/2021 21:42:18 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:42:18 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:18 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:42:18 - INFO - training_utils.postprocess -   1 (0.07 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:18 - INFO - __main__ -   Epoch: 0003 | Time: 0m_0s | train_loss: 5.517 | val_loss: 4.762
03/21/2021 21:42:18 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.6991836734693877, 'f1': 0.704824315629781, 'precision': 0.704824315629781, 'recall': 0.704824315629781}
03/21/2021 21:42:18 - INFO - __main__ -   	--Found new best val f1
03/21/2021 21:42:18 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:42:18 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:18 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:42:18 - INFO - training_utils.postprocess -   10 (0.71 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:18 - INFO - __main__ -   Epoch: 0004 | Time: 0m_0s | train_loss: 4.299 | val_loss: 6.965
03/21/2021 21:42:18 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.5963265306122449, 'f1': 0.6151560210228142, 'precision': 0.6151560210228142, 'recall': 0.6151560210228142}
03/21/2021 21:42:18 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:42:18 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:18 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:42:18 - INFO - training_utils.postprocess -   113 (8.07 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:18 - INFO - __main__ -   Epoch: 0005 | Time: 0m_0s | train_loss: 3.839 | val_loss: 4.637
03/21/2021 21:42:18 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.7473469387755101, 'f1': 0.7566368250121637, 'precision': 0.7566368250121637, 'recall': 0.7566368250121637}
03/21/2021 21:42:18 - INFO - __main__ -   	--Found new best val f1
03/21/2021 21:42:19 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:42:19 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:19 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:42:19 - INFO - training_utils.postprocess -   95 (6.79 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:19 - INFO - __main__ -   Epoch: 0006 | Time: 0m_0s | train_loss: 1.675 | val_loss: 10.920
03/21/2021 21:42:19 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.4783673469387755, 'f1': 0.5081403330893093, 'precision': 0.5081403330893093, 'recall': 0.5081403330893093}
03/21/2021 21:42:19 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:42:19 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:19 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:42:19 - INFO - training_utils.postprocess -   112 (8.00 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:19 - INFO - __main__ -   Epoch: 0007 | Time: 0m_0s | train_loss: 1.522 | val_loss: 10.486
03/21/2021 21:42:19 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.4897959183673469, 'f1': 0.5232946508049473, 'precision': 0.5232946508049473, 'recall': 0.5232946508049473}
03/21/2021 21:42:19 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:42:19 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:19 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:42:19 - INFO - training_utils.postprocess -   27 (1.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:19 - INFO - __main__ -   Epoch: 0008 | Time: 0m_0s | train_loss: 1.199 | val_loss: 10.217
03/21/2021 21:42:19 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.5383673469387754, 'f1': 0.5837067025444111, 'precision': 0.5837067025444111, 'recall': 0.5837067025444111}
03/21/2021 21:42:19 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:42:19 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:19 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:42:19 - INFO - training_utils.postprocess -   1 (0.07 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:19 - INFO - __main__ -   Epoch: 0009 | Time: 0m_0s | train_loss: 0.939 | val_loss: 10.328
03/21/2021 21:42:19 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.5910204081632653, 'f1': 0.6365414979117489, 'precision': 0.6365414979117489, 'recall': 0.6365414979117489}
03/21/2021 21:42:20 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:42:20 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:20 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:42:20 - INFO - training_utils.postprocess -   1 (0.07 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:20 - INFO - __main__ -   Epoch: 0010 | Time: 0m_0s | train_loss: 0.420 | val_loss: 11.507
03/21/2021 21:42:20 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.5628571428571428, 'f1': 0.6068871231692338, 'precision': 0.6068871231692338, 'recall': 0.6068871231692338}
03/21/2021 21:42:20 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:42:20 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:20 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:42:20 - INFO - training_utils.postprocess -   6 (0.43 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:20 - INFO - __main__ -   Epoch: 0011 | Time: 0m_0s | train_loss: 0.411 | val_loss: 12.056
03/21/2021 21:42:20 - INFO - __main__ -   ğŸ“£ val metrics ğŸ“£ {'acc': 0.5636734693877551, 'f1': 0.6056145673256009, 'precision': 0.6056145673256009, 'recall': 0.6056145673256009}
03/21/2021 21:42:20 - INFO - __main__ -   	--STOPPING EARLY
03/21/2021 21:42:20 - INFO - __main__ -   load checkpoint from ../models/arbg/transformer_encoder/few50_hidden256_vocab32000
03/21/2021 21:42:20 - INFO - __main__ -   load model weights from checkpoint in ../models/arbg/transformer_encoder/few50_hidden256_vocab32000
03/21/2021 21:42:20 - INFO - training_utils.train_loop -   postprocessing targets..
03/21/2021 21:42:20 - INFO - training_utils.postprocess -   13 (0.93 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:20 - INFO - training_utils.train_loop -   postprocessing predictions..
03/21/2021 21:42:20 - INFO - training_utils.postprocess -   113 (8.07 %) out of 1400 q2, q3, q4, q5 predictions are changed during postprocessing
03/21/2021 21:42:20 - INFO - __main__ -   best_val_loss: 4.637
03/21/2021 21:42:20 - INFO - __main__ -   ğŸ“£ best validation metrics ğŸ“£ {'acc': 0.7473469387755101, 'f1': 0.7566368250121637, 'precision': 0.7566368250121637, 'recall': 0.7566368250121637}
